{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression is Classification algorithm commonly used in Machine Learning. It allows categorizing data into discrete classes by learning the relationship from a given set of labeled data. It learns a linear relationship from the given dataset and then introduces a non-linearity in the form of the Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "def sigmoid(z): \n",
    "    return 1 / (1 + np.exp( - z)) \n",
    "  \n",
    "plt.plot(np.arange(-5, 5, 0.1), sigmoid(np.arange(-5, 5, 0.1))) \n",
    "plt.title('Visualization of the Sigmoid Function') \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "The iris flower dataset is available on Keras dataset API(https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) The following code loads the Iris dataset to your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# import iris data from sklearn datasets library\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# To use tenforflow 1.x functions, import compact v1\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.enable_eager_execution()\n",
    "# # # make unable to use tensorflow v2.x functions to avoid crash\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# change to pandas dataframe\n",
    "iris = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "iris = iris.astype({\"target\": int })\n",
    "\n",
    "print(iris)\n",
    "print(iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t<style> \n",
       "\t.table {\n",
       "      border-collapse: collapse;\n",
       "      border: #d0d4d5 solid 1px;\n",
       "      border-spacing: 0px;\n",
       "      font: Arial;\n",
       "      text-align: center;\n",
       "      padding: 5px;\n",
       "      width: 100%;\n",
       "    }\n",
       "    \n",
       "\n",
       "    .headerRowStyle {\n",
       "      background-color: #fff;\n",
       "      border-bottom: 3px solid #ccc;\n",
       "      color: #4078a9;\n",
       "      font-size: 14px;\n",
       "      height: 48px;\n",
       "      line-height: 14px;\n",
       "      padding: 10px 5px 5px 5px\n",
       "    }\n",
       "    \n",
       "    .headerCellStyle {\n",
       "      border-left: 1px solid #d0d4d5;\n",
       "    }\n",
       "    \n",
       "    .tableRowStyle {\n",
       "      border-bottom: 1px solid #d0d4d5;\n",
       "      color: #565656;\n",
       "    }\n",
       "\t\t </style>\n",
       "\t\t<h1> Vector Visualization </h1>\n",
       "\t\t<div class=\"tables\"></div>\n",
       "\n",
       "\t\t<script> \n",
       "\t\tconsole.log(\"Loading JavaScript...\")\n",
       "\t\tconsole.log(\"Loaded Data:\")\n",
       "        var dname = \"libraries/iris.json\"\n",
       "\n",
       "    function colorPicker(value) {\n",
       "        if (value == \"Iris-setosa\") {\n",
       "        return \"#7aa25c\";\n",
       "        } else if (value == \"Iris-versicolor\") {\n",
       "        return \"#f4f85e\";\n",
       "        } else {\n",
       "        return \"#d84b2a\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "\n",
       "    function checkNumberIfFloat(value) {\n",
       "        return Number(value) === value && value % 1 !== 0;\n",
       "    }\n",
       "\n",
       "    d3.json(\"libraries/iris.json\", function(dataSet) {\n",
       "      var div = d3.select('.tables');\n",
       "\n",
       "      // append a table to the div\n",
       "      var table = div.append(\"table\")\n",
       "        .attr({\n",
       "          id: \"sample\",\n",
       "          class: 'table'\n",
       "        })\n",
       "        .classed(\"display\", true);\n",
       "\n",
       "      // append a header to the table\n",
       "      var thead = table.append(\"thead\")\n",
       "\n",
       "      // append a body to the table\n",
       "      var tbody = table.append(\"tbody\")\n",
       "\n",
       "      // append a row to the header\n",
       "      var theadRow = thead.append(\"tr\")\n",
       "        .attr({\n",
       "          class: 'headerRowStyle'\n",
       "        });\n",
       "\n",
       "      // return a selection of cell elements in the header row\n",
       "      // attribute (join) data to the selection\n",
       "      // update (enter) the selection with nodes that have data\n",
       "      // append the cell elements to the header row\n",
       "      // return the text string for each item in the data array\n",
       "      theadRow.selectAll(\"th\")\n",
       "        .data(d3.keys(dataSet[0]))\n",
       "        .enter()\n",
       "        .append(\"th\")\n",
       "        .text(function(d) {\n",
       "          return d;\n",
       "        });\n",
       "\n",
       "      // table body rows\n",
       "      var tableBodyRows = tbody.selectAll(\"tr\")\n",
       "        .data(dataSet)\n",
       "        .enter()\n",
       "        .append(\"tr\")\n",
       "        .attr({\n",
       "          class: 'tableRowStyle'\n",
       "        });\n",
       "\n",
       "      //table body row cells\n",
       "      tableBodyRows.selectAll(\"td\")\n",
       "        .data(function(d) {\n",
       "          return d3.values(d);\n",
       "        })\n",
       "        .enter()\n",
       "        .append(\"td\")\n",
       "        .text(function(d) {\n",
       "          return d;\n",
       "        })\n",
       "        .append(function(d) {\n",
       "          return createSVG(d);\n",
       "        });\n",
       "        \n",
       "    })\n",
       "\n",
       "    function createSVG(d) {\n",
       "      var w = 75;\n",
       "      var h = 75;\n",
       "\n",
       "      var kpi = document.createElement(\"div\");\n",
       "\n",
       "      var svg = d3.select(kpi).append(\"svg\")\n",
       "        .attr({\n",
       "          width: w,\n",
       "          height: h\n",
       "        });\n",
       "        \n",
       "      var elem = svg.selectAll(\"div\")\n",
       "        .data([d]);\n",
       "\n",
       "      var elemEnter = elem.enter()\n",
       "        .append(\"g\");\n",
       "\n",
       "    \n",
       "        if( checkNumberIfFloat(d) || Number.isInteger(d)){\n",
       "            var la = (d/7);\n",
       "            elemEnter.append(\"rect\")\n",
       "                .attr({\n",
       "                x: 25,\n",
       "                y: 10, //this basically makes the svg start from the button instead of the top\n",
       "                width: 60*la,\n",
       "                height: 20\n",
       "                })\n",
       "                .style(\"fill\", \"#4078a9\");\n",
       "\n",
       "            elemEnter.append(\"text\")\n",
       "                .style(\"fill\", \"blue\")\n",
       "                .attr(\"dy\", 30)\n",
       "                .attr(\"dx\", 25)\n",
       "        }else{ \n",
       "            elemEnter.append(\"circle\")\n",
       "                .attr({\n",
       "                cx: 28,\n",
       "                cy: 25,\n",
       "                r: 20\n",
       "                })\n",
       "                .style(\"fill\", colorPicker);\n",
       "\n",
       "            elemEnter.append(\"text\")\n",
       "                .style(\"fill\", \"blue\")\n",
       "                .attr(\"dy\", 30)\n",
       "                .attr(\"dx\", 25)\n",
       "\n",
       "        }\n",
       "      return kpi;\n",
       "    }\n",
       "\t\t </script>\n",
       "\t\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_directory = \"libraries/\"\n",
    "output_filename = \"iris.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import libraries.vector as vector\n",
    "\n",
    "cm = vector.Visualization(full_path)\n",
    "cm.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## Explore the data \n",
    "\n",
    "Let's take a moment to understand the format of the data. Each data contains sepal length, sepal width, petal length, petal width and a corresponding species label. The label is an integer value of either 0 or 1, where 0 is a 'Iris-setosa', and 1 is a 'Iris-versicolo'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check head of dataframe\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a scatter plot with sepal length and width between two iris species in the dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(iris['sepal length (cm)'][:50], iris['sepal width (cm)'][:50], label='Iris-setosa')\n",
    "plt.scatter(iris['sepal length (cm)'][51:], iris['sepal width (cm)'][51:], label='Iris-versicolo')\n",
    "plt.scatter(iris['sepal length (cm)'][101:], iris['sepal width (cm)'][101:], label='Iris-virginica')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5bmxzE0Fobd"
   },
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create x value as the features and y value as species (labels) from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop(labels=['target'], axis=1).values\n",
    "y = iris['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a seed to get reproducibility for numpy and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, split the dataset into trainset (60%) and testset (40%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random choice from numpy library to set dataset randomly\n",
    "train_data = np.random.choice(len(x), round(len(x) * 0.6), replace=False)\n",
    "test_data = np.array(list(set(range(len(x))) - set(train_data)))\n",
    "\n",
    "# separate the dataset into features and labels\n",
    "x_train = x[train_data]\n",
    "y_train = y[train_data]\n",
    "x_test = x[test_data]\n",
    "y_test = y[test_data]\n",
    "\n",
    "# the number of labels\n",
    "num_labels = 3 \n",
    "\n",
    "# the number of features: sepal length & width, petal length & width\n",
    "num_features = 4\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to normalize the feature values in the dataset.\n",
    "Normalization is optional for logistic regression. However, the main goal of normalizing features is to help convergence of the technique used for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalization function\n",
    "def min_max_normalization(data):\n",
    "    col_max = np.max(data, axis=0)\n",
    "    col_min = np.min(data, axis=0)\n",
    "    return np.divide(data - col_min, col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized processing, must be placed after the data set segmentation, \n",
    "# otherwise the test set will be affected by the training set\n",
    "x_train = min_max_normalization(x_train)\n",
    "x_test = min_max_normalization(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## Build the model\n",
    "With the pre-processed dataset, we start to build the model with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin building the model framework\n",
    "# Declare the variables that need to be learned and initialization\n",
    "# Weight of shape [4, 3]\n",
    "\n",
    "W = tf.Variable(tf.ones([num_features, num_labels]), name=\"weight\")\n",
    "\n",
    "# Bias of shape [3], the total number of classes.\n",
    "\n",
    "b = tf.Variable(tf.zeros([num_labels]), name=\"bias\")\n",
    "\n",
    "#W = tf.Variable(tf.random.normal([2, 1], mean=0.0))\n",
    "#b = tf.Variable(tf.random.normal([1], mean=0.0))\n",
    "# The tf 2.x doesn't need to use tf.global_variables_initializer() and place holders\n",
    "#init = tf.global_variables_initializer()\n",
    "#sess = tf.Session()\n",
    "#sess.run(init)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the logistic regression to learn about variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (Wx + b).\n",
    "\n",
    "def logistic_regression(x):\n",
    "\n",
    "    # Apply softmax to normalize the logits to a probability distribution.\n",
    "\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "attachments": {
    "log_loss.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer\n",
    "\n",
    "Let's declare the loss function\n",
    "\n",
    "The loss function is critical for machine & deep learning models.\n",
    "The loss function for linear regression is squared loss, but the loss function for logistic regression is Log Loss, which is defined as follows:\n",
    "\n",
    "![log_loss.PNG](attachment:log_loss.PNG)\n",
    "\n",
    "where:\n",
    "\n",
    "* (x,y) ∈ D is the data set containing many labeled examples, which are  (x,y) pairs.\n",
    "* y is the label in a labeled example. Since this is logistic regression, every value of y must either be 0 or 1.\n",
    "* y' is the predicted value (somewhere between 0 and 1), given the set of features in x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy loss function.\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "\n",
    "    # Encode label to a one hot vector.\n",
    "\n",
    "    y_true = tf.one_hot(y_true, depth=num_labels)\n",
    "\n",
    "    # Clip prediction values to avoid log(0) error.\n",
    "\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "\n",
    "    # Compute cross-entropy.\n",
    "\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before train our model, we need to set the parameters: learning rate, batch size, and the number of epoch interations.\n",
    "\n",
    "\n",
    "* Learning rate is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient.\n",
    "\n",
    "* Batch size defines the number of samples that will be propagated through the network.\n",
    "\n",
    "* An epoch is a full iteration over samples during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "batch_size = 32\n",
    "epoch_iteration_num = 2000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define optimizer to find optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metric.\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "\n",
    "# Predicted class is the index of the highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "\n",
    "train_data=tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "\n",
    "train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "\n",
    "# create variables to store result\n",
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# Optimization process. \n",
    "\n",
    "def run_optimization(x, y):\n",
    "\n",
    "# Wrap computation inside a GradientTape for automatic differentiation.\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "\n",
    "        pred = logistic_regression(x)\n",
    "\n",
    "        loss = cross_entropy(pred, y)\n",
    "        losses.append(loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "\n",
    "  \n",
    "\n",
    "    # Update W and b following gradients.\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for the given number of steps.\n",
    "\n",
    "for epoch, (batch_x, batch_y) in enumerate(train_data.take(epoch_iteration_num), 1):\n",
    "\n",
    "    # Run the optimization to update W and b values.\n",
    "\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    train_pred = logistic_regression(batch_x)\n",
    "    train_acc = accuracy(train_pred, batch_y)\n",
    "    test_pred = logistic_regression(x_test)\n",
    "    test_acc = accuracy(test_pred, y_test)\n",
    "    # recode the result\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    \n",
    "\n",
    "    if epoch % display_step == 0:\n",
    "\n",
    "        #pred = logistic_regression(batch_x)\n",
    "\n",
    "        loss = cross_entropy(train_pred, batch_y)\n",
    "\n",
    "\n",
    "        #print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
    "        print('epoch: {:4d} loss: {:5f} train accuracy: {:5f} test accuracy: {:5f}'.format(epoch, loss,\n",
    "                                                                          train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make plot of the loss per epoch from the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs, 'b-', label='train accuracy')\n",
    "plt.plot(test_accs, 'r-', label='test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on validation set.\n",
    "model_prediction = []\n",
    "testing_predictions = ((logistic_regression(x_test) > 0.5).numpy()).astype(\"int32\")\n",
    "\n",
    "for i in range(len(testing_predictions)):\n",
    "    for j in range(len(testing_predictions[i])):\n",
    "        if testing_predictions[i][j] == 1:\n",
    "            model_prediction.append(j)\n",
    "\n",
    "pred = logistic_regression(x_test)\n",
    "probas = pred.numpy()\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_directory = \"libraries/\"\n",
    "output_filename = \"predict_LR.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "data = []\n",
    "data.extend([{\n",
    "      'index': i,\n",
    "      'true_label': int(y_test[i]),\n",
    "      'predicted_label': model_prediction[i],\n",
    "      'confidence_score': probas.tolist()[i],\n",
    "      'text': str(x_test.tolist()[i])\n",
    "  } for i in range(len(testing_predictions))])\n",
    "\n",
    "\n",
    "with open(full_path, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=8, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------easy way (don't run yet) -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "# Predict probabilities\n",
    "probs_y=classifier.predict_proba(x_test)\n",
    "### Print results \n",
    "probs_y = np.round(probs_y, 2)\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(y_test, y_pred, probs_y[:,0], probs_y[:,1], probs_y[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "import seaborn as sns\n",
    "# confusion matrix sns heatmap \n",
    "ax = plt.axes()\n",
    "df_cm = cm\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 30}, fmt='d',cmap=\"Blues\", ax = ax )\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
