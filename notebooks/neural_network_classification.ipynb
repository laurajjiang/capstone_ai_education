{
 "cells": [
  {
   "source": [
    "# Creating a Neural Network for Classification \n",
    "\n",
    "In this notebook, we'll learn how to create a neural network for multi-categorical classification using the Iris dataset. This is the same dataset that was explored in the Logistic Regression notebook, but now using an entirely different models. The ideas are the same, however, so if you'd like extra support refer back to the Logistic Regression notebook where concepts like loss and optimization are broken down a bit more.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We'll start off by importing some libraries that will be helpful for us to build out our model. `sklearn` (scikitlearn) is another helpful machine learning-related library, and will be where we get the Iris dataset from."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LEVo4pdsKkNb"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4f4e29896b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-transaction",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "The Iris flower dataset is available on the [Keras dataset API](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) if you'd like to see the raw HTML.\n",
    "\n",
    "The following code loads the Iris dataset onto this notebook. We'll peek at what this dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tnms8RR7KkaF",
    "outputId": "b42a1b41-0df6-4163-c016-a9e7542f1b2f"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "iris = iris.astype({\"target\": int })\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-premiere",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## Explore the data \n",
    "\n",
    "Let's take a moment to understand the format of the data. Each data contains sepal length, sepal width, petal length, petal width and a corresponding species label. The label is an integer value of either 0, 1, or 2 where 0 is a `Iris-setosa`, 1 is a `Iris-versicolo`, and 2 is a `Iris-virginica.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "_tVdpyFQKkd3",
    "outputId": "0c4b678a-f1c0-4af5-80df-e7dbe98507e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2cf6229a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iris['sepal length (cm)'][:50], iris['sepal width (cm)'][:50], label='Iris-setosa')\n",
    "plt.scatter(iris['sepal length (cm)'][51:], iris['sepal width (cm)'][51:], label='Iris-versicolo')\n",
    "plt.scatter(iris['sepal length (cm)'][101:], iris['sepal width (cm)'][101:], label='Iris-virginica')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "source": [
    "The following two code blocks help us set up our data to use as input into our neural network model. You can refer back to the Logistic Regression notebook for an explanation on encoding our data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CzpqD0zXVKIT"
   },
   "outputs": [],
   "source": [
    "x = iris.drop(labels=['target'], axis=1).values\n",
    "y_ = iris['target'].values.reshape(-1, 1)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y_)"
   ]
  },
  {
   "source": [
    "Here, we're splitting the whole Iris dataset into a training set and a test set. The training set is a bit smaller than our test set, containing 20% of the original dataset while the other 80% will be used in testing our model. \n",
    "\n",
    "Feel free to change these values and see how the accuracy and loss of our model changes later down the road."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iAldyTxES7jR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "x, y = shuffle(x, y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.8)"
   ]
  },
  {
   "source": [
    "## Building our neural network \n",
    "\n",
    "Finally, we can start to build a simple neural network. We'll use Tensorflow Keras to build our model. \n",
    "\n",
    "Overall, we have 4 layers to our neural network. The first layer is the input layer that we've named aptly. The activation function is the ReLU (Rectified Linear Unit) function, which is commonly used for neural networks. The input shape is `(4,),` representing the four features (sepal length, sepal width, petal length, petal width) we're interested in looking at to classify which Iris category the current array represents. \n",
    "\n",
    "Next, we have two \"hidden layers,\" or two layers sandwiched between our input and output layer. They also have a ReLU activation function. These hidden layers help the neural network break down the incoming data into unique parts to help the whole neural network better understand how to classify the piece of data. \n",
    "\n",
    "Lastly, we have the output layer. There are three nodes in our output layer, alongside a new activation function (`softmax`). `Softmax` helps to normalize our output probability in the 0-1 range so we can understand the output of our function better. Because we are using `softmax,` we need one node per category label. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gG8mdEugMrMm",
    "outputId": "c9dca994-48c4-4e5b-afb7-2baa17d76c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "hidden-1 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "hidden-2 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,), name='input'),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, name='hidden-1'),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, name='hidden-2'),\n",
    "  tf.keras.layers.Dense(3, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "source": [
    "We can see what the output of our hidden layers looks like. The whole `predictions` array holds an array of vectors, where each vector is the hidden layers' probability calculations. The index of the array (0, 1, or 2) represents the calculated probability that the inputted data corresponds to that category of Iris, where 0 is a `Iris-setosa`, 1 is a `Iris-versicolo`, and 2 is a `Iris-virginica.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pe0MwRUiVukG",
    "outputId": "c9dead44-cf29-4720-a63c-7f7413da2221",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.265216  , 0.24151523, 0.4932688 ],\n",
       "       [0.25755143, 0.23534136, 0.50710726],\n",
       "       [0.31570503, 0.2655454 , 0.41874954],\n",
       "       [0.2752816 , 0.2490699 , 0.47564843],\n",
       "       [0.2801358 , 0.25202224, 0.46784198]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden layer vector\n",
    "\n",
    "predictions = model(x)\n",
    "tf.nn.softmax(predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-desert",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "The next step is to train our model. We'll use a built-in optimizer to optimize our model with stochastic gradient descent (SGD), updating the parameters in our neural network through backpropogation. Backpropogation is essentially seeing our neural network reacts to changing the weights and biases within our model. Understanding the math behind backpropogation is more math-heavy, so we won't cover it too in-depth here. Refer to the site for more detail. \n",
    "\n",
    "We've also chosen to use a built-in a loss function (categorical cross-entropy loss). Cross-entropy loss, shown in the Logisitic Regression notebook, is used for binary classification while categorical cross-entropy loss is for multi-categorical classification such as this iris problem (we have three different classes). \n",
    "\n",
    "Feel free to play around with different optimizers and loss functions. You can find the full documentation on the Tensorflow site: [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) and [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1aeXZD8MrbA",
    "outputId": "7c70bcca-d816-47c0-d706-0b8cd392bf8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3616 - accuracy: 0.3810 - val_loss: 1.3850 - val_accuracy: 0.2222\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2207 - accuracy: 0.3810 - val_loss: 1.2874 - val_accuracy: 0.2222\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1369 - accuracy: 0.3810 - val_loss: 1.2281 - val_accuracy: 0.2222\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0900 - accuracy: 0.3810 - val_loss: 1.1920 - val_accuracy: 0.2222\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0613 - accuracy: 0.3810 - val_loss: 1.1718 - val_accuracy: 0.2222\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0386 - accuracy: 0.3810 - val_loss: 1.1479 - val_accuracy: 0.2222\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0185 - accuracy: 0.3810 - val_loss: 1.1308 - val_accuracy: 0.2222\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0009 - accuracy: 0.3810 - val_loss: 1.1192 - val_accuracy: 0.2222\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9866 - accuracy: 0.3810 - val_loss: 1.1028 - val_accuracy: 0.2222\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9748 - accuracy: 0.3810 - val_loss: 1.0968 - val_accuracy: 0.2222\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9651 - accuracy: 0.3810 - val_loss: 1.0827 - val_accuracy: 0.2222\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9567 - accuracy: 0.3810 - val_loss: 1.0801 - val_accuracy: 0.2222\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9494 - accuracy: 0.3810 - val_loss: 1.0710 - val_accuracy: 0.2222\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9425 - accuracy: 0.3810 - val_loss: 1.0616 - val_accuracy: 0.2222\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9368 - accuracy: 0.3810 - val_loss: 1.0586 - val_accuracy: 0.2222\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9312 - accuracy: 0.3810 - val_loss: 1.0500 - val_accuracy: 0.2222\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9256 - accuracy: 0.3810 - val_loss: 1.0437 - val_accuracy: 0.2222\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9203 - accuracy: 0.3810 - val_loss: 1.0357 - val_accuracy: 0.2222\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9154 - accuracy: 0.3810 - val_loss: 1.0328 - val_accuracy: 0.2222\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9101 - accuracy: 0.3810 - val_loss: 1.0271 - val_accuracy: 0.2222\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9052 - accuracy: 0.3810 - val_loss: 1.0233 - val_accuracy: 0.2222\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9006 - accuracy: 0.3810 - val_loss: 1.0198 - val_accuracy: 0.2222\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8961 - accuracy: 0.3810 - val_loss: 1.0174 - val_accuracy: 0.2222\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8917 - accuracy: 0.3810 - val_loss: 1.0152 - val_accuracy: 0.2222\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8874 - accuracy: 0.3810 - val_loss: 1.0120 - val_accuracy: 0.2222\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8833 - accuracy: 0.3810 - val_loss: 1.0079 - val_accuracy: 0.2222\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8795 - accuracy: 0.3810 - val_loss: 1.0040 - val_accuracy: 0.2222\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8756 - accuracy: 0.3810 - val_loss: 0.9997 - val_accuracy: 0.2222\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8717 - accuracy: 0.3810 - val_loss: 0.9958 - val_accuracy: 0.2222\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8679 - accuracy: 0.3810 - val_loss: 0.9924 - val_accuracy: 0.2222\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8642 - accuracy: 0.3810 - val_loss: 0.9892 - val_accuracy: 0.2222\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8606 - accuracy: 0.4762 - val_loss: 0.9861 - val_accuracy: 0.2222\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8570 - accuracy: 0.4762 - val_loss: 0.9839 - val_accuracy: 0.2222\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8536 - accuracy: 0.4762 - val_loss: 0.9810 - val_accuracy: 0.2222\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8503 - accuracy: 0.52 - 0s 54ms/step - loss: 0.8503 - accuracy: 0.5238 - val_loss: 0.9789 - val_accuracy: 0.2222\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8470 - accuracy: 0.5238 - val_loss: 0.9762 - val_accuracy: 0.2222\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8442 - accuracy: 0.5238 - val_loss: 0.9733 - val_accuracy: 0.2222\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8414 - accuracy: 0.5238 - val_loss: 0.9699 - val_accuracy: 0.2222\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8388 - accuracy: 0.5238 - val_loss: 0.9676 - val_accuracy: 0.2222\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8362 - accuracy: 0.5238 - val_loss: 0.9646 - val_accuracy: 0.2222\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8337 - accuracy: 0.5238 - val_loss: 0.9624 - val_accuracy: 0.2222\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8312 - accuracy: 0.5238 - val_loss: 0.9597 - val_accuracy: 0.2222\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8288 - accuracy: 0.5238 - val_loss: 0.9585 - val_accuracy: 0.2222\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8266 - accuracy: 0.5238 - val_loss: 0.9540 - val_accuracy: 0.2222\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8243 - accuracy: 0.5238 - val_loss: 0.9528 - val_accuracy: 0.2222\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8219 - accuracy: 0.5238 - val_loss: 0.9493 - val_accuracy: 0.2222\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8198 - accuracy: 0.5714 - val_loss: 0.9475 - val_accuracy: 0.2222\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8177 - accuracy: 0.5714 - val_loss: 0.9448 - val_accuracy: 0.2222\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8156 - accuracy: 0.5714 - val_loss: 0.9435 - val_accuracy: 0.2222\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8134 - accuracy: 0.5714 - val_loss: 0.9394 - val_accuracy: 0.2222\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8113 - accuracy: 0.7143 - val_loss: 0.9383 - val_accuracy: 0.2222\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8091 - accuracy: 0.6190 - val_loss: 0.9365 - val_accuracy: 0.2222\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8071 - accuracy: 0.6190 - val_loss: 0.9349 - val_accuracy: 0.4444\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8052 - accuracy: 0.6190 - val_loss: 0.9327 - val_accuracy: 0.5556\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8034 - accuracy: 0.6667 - val_loss: 0.9311 - val_accuracy: 0.5556\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8015 - accuracy: 0.6667 - val_loss: 0.9295 - val_accuracy: 0.5556\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7996 - accuracy: 0.6190 - val_loss: 0.9278 - val_accuracy: 0.5556\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7977 - accuracy: 0.6667 - val_loss: 0.9261 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7959 - accuracy: 0.6667 - val_loss: 0.9243 - val_accuracy: 0.5556\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7941 - accuracy: 0.6667 - val_loss: 0.9227 - val_accuracy: 0.5556\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7922 - accuracy: 0.6667 - val_loss: 0.9208 - val_accuracy: 0.5556\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7904 - accuracy: 0.7143 - val_loss: 0.9192 - val_accuracy: 0.5556\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7886 - accuracy: 0.7143 - val_loss: 0.9174 - val_accuracy: 0.5556\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7868 - accuracy: 0.7143 - val_loss: 0.9157 - val_accuracy: 0.5556\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7850 - accuracy: 0.7143 - val_loss: 0.9142 - val_accuracy: 0.5556\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7833 - accuracy: 0.7143 - val_loss: 0.9124 - val_accuracy: 0.5556\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7815 - accuracy: 0.7619 - val_loss: 0.9106 - val_accuracy: 0.5556\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7797 - accuracy: 0.7619 - val_loss: 0.9090 - val_accuracy: 0.5556\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7780 - accuracy: 0.7619 - val_loss: 0.9072 - val_accuracy: 0.5556\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7762 - accuracy: 0.80 - 0s 63ms/step - loss: 0.7762 - accuracy: 0.8095 - val_loss: 0.9053 - val_accuracy: 0.5556\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7744 - accuracy: 0.8095 - val_loss: 0.9034 - val_accuracy: 0.5556\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7727 - accuracy: 0.8095 - val_loss: 0.9018 - val_accuracy: 0.6667\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7709 - accuracy: 0.8095 - val_loss: 0.8999 - val_accuracy: 0.6667\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7692 - accuracy: 0.8095 - val_loss: 0.8979 - val_accuracy: 0.6667\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7674 - accuracy: 0.8095 - val_loss: 0.8960 - val_accuracy: 0.6667\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7656 - accuracy: 0.8095 - val_loss: 0.8943 - val_accuracy: 0.6667\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7639 - accuracy: 0.8095 - val_loss: 0.8923 - val_accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7621 - accuracy: 0.8095 - val_loss: 0.8904 - val_accuracy: 0.6667\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7603 - accuracy: 0.8571 - val_loss: 0.8884 - val_accuracy: 0.6667\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7586 - accuracy: 0.9048 - val_loss: 0.8864 - val_accuracy: 0.6667\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7568 - accuracy: 0.9048 - val_loss: 0.8844 - val_accuracy: 0.6667\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7550 - accuracy: 0.9048 - val_loss: 0.8827 - val_accuracy: 0.6667\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7533 - accuracy: 0.9048 - val_loss: 0.8808 - val_accuracy: 0.6667\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7515 - accuracy: 0.9048 - val_loss: 0.8788 - val_accuracy: 0.6667\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7497 - accuracy: 0.9048 - val_loss: 0.8769 - val_accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7479 - accuracy: 0.9048 - val_loss: 0.8749 - val_accuracy: 0.6667\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7461 - accuracy: 0.9048 - val_loss: 0.8730 - val_accuracy: 0.6667\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7443 - accuracy: 0.9048 - val_loss: 0.8713 - val_accuracy: 0.6667\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7425 - accuracy: 0.9048 - val_loss: 0.8699 - val_accuracy: 0.6667\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7407 - accuracy: 0.9048 - val_loss: 0.8682 - val_accuracy: 0.6667\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7389 - accuracy: 0.9048 - val_loss: 0.8665 - val_accuracy: 0.6667\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7371 - accuracy: 0.9048 - val_loss: 0.8650 - val_accuracy: 0.6667\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7355 - accuracy: 0.9048 - val_loss: 0.8632 - val_accuracy: 0.6667\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7336 - accuracy: 0.9048 - val_loss: 0.8614 - val_accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7320 - accuracy: 0.9048 - val_loss: 0.8608 - val_accuracy: 0.6667\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7302 - accuracy: 0.8571 - val_loss: 0.8588 - val_accuracy: 0.6667\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7285 - accuracy: 0.9048 - val_loss: 0.8573 - val_accuracy: 0.6667\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7267 - accuracy: 0.9048 - val_loss: 0.8555 - val_accuracy: 0.6667\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7251 - accuracy: 0.9524 - val_loss: 0.8540 - val_accuracy: 0.6667\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7233 - accuracy: 0.9524 - val_loss: 0.8524 - val_accuracy: 0.6667\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7216 - accuracy: 0.9048 - val_loss: 0.8506 - val_accuracy: 0.6667\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7199 - accuracy: 0.9524 - val_loss: 0.8501 - val_accuracy: 0.6667\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7182 - accuracy: 0.9048 - val_loss: 0.8483 - val_accuracy: 0.6667\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7165 - accuracy: 0.9524 - val_loss: 0.8463 - val_accuracy: 0.6667\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7148 - accuracy: 0.9524 - val_loss: 0.8448 - val_accuracy: 0.6667\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7130 - accuracy: 0.9524 - val_loss: 0.8432 - val_accuracy: 0.6667\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7113 - accuracy: 0.9524 - val_loss: 0.8427 - val_accuracy: 0.6667\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7097 - accuracy: 0.9048 - val_loss: 0.8406 - val_accuracy: 0.6667\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7081 - accuracy: 0.9524 - val_loss: 0.8390 - val_accuracy: 0.6667\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7064 - accuracy: 0.9524 - val_loss: 0.8374 - val_accuracy: 0.6667\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7048 - accuracy: 0.9524 - val_loss: 0.8357 - val_accuracy: 0.6667\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7032 - accuracy: 0.9524 - val_loss: 0.8339 - val_accuracy: 0.6667\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7016 - accuracy: 0.9524 - val_loss: 0.8332 - val_accuracy: 0.6667\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7000 - accuracy: 0.9524 - val_loss: 0.8315 - val_accuracy: 0.6667\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6983 - accuracy: 0.9524 - val_loss: 0.8296 - val_accuracy: 0.6667\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6969 - accuracy: 0.9524 - val_loss: 0.8277 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6953 - accuracy: 0.9524 - val_loss: 0.8262 - val_accuracy: 0.6667\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6937 - accuracy: 0.9524 - val_loss: 0.8248 - val_accuracy: 0.6667\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6921 - accuracy: 0.9524 - val_loss: 0.8243 - val_accuracy: 0.6667\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6906 - accuracy: 0.9524 - val_loss: 0.8226 - val_accuracy: 0.6667\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6891 - accuracy: 0.9524 - val_loss: 0.8209 - val_accuracy: 0.6667\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6876 - accuracy: 0.9524 - val_loss: 0.8190 - val_accuracy: 0.7778\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6861 - accuracy: 0.9524 - val_loss: 0.8177 - val_accuracy: 0.7778\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6845 - accuracy: 0.9524 - val_loss: 0.8163 - val_accuracy: 0.7778\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6830 - accuracy: 0.9524 - val_loss: 0.8150 - val_accuracy: 0.7778\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6815 - accuracy: 0.9524 - val_loss: 0.8136 - val_accuracy: 0.7778\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6800 - accuracy: 0.9524 - val_loss: 0.8120 - val_accuracy: 0.7778\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6785 - accuracy: 0.9524 - val_loss: 0.8106 - val_accuracy: 0.7778\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6770 - accuracy: 0.9524 - val_loss: 0.8092 - val_accuracy: 0.7778\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6755 - accuracy: 0.9524 - val_loss: 0.8076 - val_accuracy: 0.7778\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6740 - accuracy: 0.9524 - val_loss: 0.8063 - val_accuracy: 0.7778\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6725 - accuracy: 0.9524 - val_loss: 0.8049 - val_accuracy: 0.7778\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6710 - accuracy: 0.9524 - val_loss: 0.8033 - val_accuracy: 0.7778\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6695 - accuracy: 0.9524 - val_loss: 0.8020 - val_accuracy: 0.7778\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6681 - accuracy: 0.9524 - val_loss: 0.8003 - val_accuracy: 0.7778\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6666 - accuracy: 0.9524 - val_loss: 0.7990 - val_accuracy: 0.7778\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6651 - accuracy: 0.9524 - val_loss: 0.7977 - val_accuracy: 0.7778\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6636 - accuracy: 0.9524 - val_loss: 0.7961 - val_accuracy: 0.7778\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6621 - accuracy: 0.9524 - val_loss: 0.7948 - val_accuracy: 0.7778\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6606 - accuracy: 0.9524 - val_loss: 0.7931 - val_accuracy: 0.7778\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6591 - accuracy: 0.9524 - val_loss: 0.7918 - val_accuracy: 0.7778\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6577 - accuracy: 0.9524 - val_loss: 0.7902 - val_accuracy: 0.7778\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6562 - accuracy: 0.9524 - val_loss: 0.7890 - val_accuracy: 0.7778\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6547 - accuracy: 0.9524 - val_loss: 0.7873 - val_accuracy: 0.7778\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6532 - accuracy: 0.9524 - val_loss: 0.7861 - val_accuracy: 0.7778\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6517 - accuracy: 0.9524 - val_loss: 0.7845 - val_accuracy: 0.7778\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6502 - accuracy: 0.9524 - val_loss: 0.7833 - val_accuracy: 0.7778\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6487 - accuracy: 0.9524 - val_loss: 0.7817 - val_accuracy: 0.7778\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6472 - accuracy: 0.9524 - val_loss: 0.7805 - val_accuracy: 0.7778\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6457 - accuracy: 0.9524 - val_loss: 0.7789 - val_accuracy: 0.7778\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6442 - accuracy: 0.9524 - val_loss: 0.7776 - val_accuracy: 0.7778\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6427 - accuracy: 0.9524 - val_loss: 0.7760 - val_accuracy: 0.7778\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6412 - accuracy: 0.9524 - val_loss: 0.7745 - val_accuracy: 0.7778\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6397 - accuracy: 0.9524 - val_loss: 0.7733 - val_accuracy: 0.7778\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6381 - accuracy: 0.9524 - val_loss: 0.7717 - val_accuracy: 0.7778\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6367 - accuracy: 0.9524 - val_loss: 0.7705 - val_accuracy: 0.7778\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6351 - accuracy: 0.9524 - val_loss: 0.7689 - val_accuracy: 0.7778\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6336 - accuracy: 0.9524 - val_loss: 0.7676 - val_accuracy: 0.7778\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6321 - accuracy: 0.9524 - val_loss: 0.7661 - val_accuracy: 0.7778\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6305 - accuracy: 0.9524 - val_loss: 0.7639 - val_accuracy: 0.7778\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6291 - accuracy: 0.9524 - val_loss: 0.7629 - val_accuracy: 0.7778\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6275 - accuracy: 0.9524 - val_loss: 0.7615 - val_accuracy: 0.7778\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6260 - accuracy: 0.9524 - val_loss: 0.7598 - val_accuracy: 0.7778\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6245 - accuracy: 0.9524 - val_loss: 0.7585 - val_accuracy: 0.7778\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6229 - accuracy: 0.9524 - val_loss: 0.7572 - val_accuracy: 0.7778\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6214 - accuracy: 0.9524 - val_loss: 0.7556 - val_accuracy: 0.7778\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6199 - accuracy: 0.9524 - val_loss: 0.7544 - val_accuracy: 0.7778\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6183 - accuracy: 0.9524 - val_loss: 0.7531 - val_accuracy: 0.7778\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6168 - accuracy: 0.9524 - val_loss: 0.7519 - val_accuracy: 0.7778\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6153 - accuracy: 0.9524 - val_loss: 0.7498 - val_accuracy: 0.7778\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6138 - accuracy: 0.9524 - val_loss: 0.7486 - val_accuracy: 0.7778\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6122 - accuracy: 0.9524 - val_loss: 0.7472 - val_accuracy: 0.7778\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6107 - accuracy: 0.9524 - val_loss: 0.7460 - val_accuracy: 0.7778\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6092 - accuracy: 0.9524 - val_loss: 0.7440 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6077 - accuracy: 0.9524 - val_loss: 0.7427 - val_accuracy: 0.7778\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6061 - accuracy: 0.9524 - val_loss: 0.7416 - val_accuracy: 0.7778\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6046 - accuracy: 0.9524 - val_loss: 0.7395 - val_accuracy: 0.7778\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6032 - accuracy: 0.9524 - val_loss: 0.7401 - val_accuracy: 0.7778\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6017 - accuracy: 0.9524 - val_loss: 0.7377 - val_accuracy: 0.7778\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6002 - accuracy: 0.9524 - val_loss: 0.7375 - val_accuracy: 0.7778\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5987 - accuracy: 0.9524 - val_loss: 0.7353 - val_accuracy: 0.7778\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5972 - accuracy: 0.9524 - val_loss: 0.7352 - val_accuracy: 0.7778\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5957 - accuracy: 0.9524 - val_loss: 0.7350 - val_accuracy: 0.7778\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5943 - accuracy: 0.9524 - val_loss: 0.7313 - val_accuracy: 0.7778\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5930 - accuracy: 0.9524 - val_loss: 0.7316 - val_accuracy: 0.7778\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5914 - accuracy: 0.9524 - val_loss: 0.7309 - val_accuracy: 0.7778\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5900 - accuracy: 0.9524 - val_loss: 0.7299 - val_accuracy: 0.7778\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5886 - accuracy: 0.9524 - val_loss: 0.7288 - val_accuracy: 0.7778\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5872 - accuracy: 0.9524 - val_loss: 0.7275 - val_accuracy: 0.7778\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5857 - accuracy: 0.9524 - val_loss: 0.7263 - val_accuracy: 0.7778\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5843 - accuracy: 0.9524 - val_loss: 0.7248 - val_accuracy: 0.7778\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5829 - accuracy: 0.9524 - val_loss: 0.7234 - val_accuracy: 0.7778\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5815 - accuracy: 0.9524 - val_loss: 0.7221 - val_accuracy: 0.7778\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5801 - accuracy: 0.9524 - val_loss: 0.7218 - val_accuracy: 0.7778\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5788 - accuracy: 0.9524 - val_loss: 0.7175 - val_accuracy: 0.7778\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5776 - accuracy: 0.9524 - val_loss: 0.7203 - val_accuracy: 0.7778\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5765 - accuracy: 0.9524 - val_loss: 0.7149 - val_accuracy: 0.7778\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5746 - accuracy: 0.9524 - val_loss: 0.7162 - val_accuracy: 0.7778\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5732 - accuracy: 0.9524 - val_loss: 0.7137 - val_accuracy: 0.7778\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5718 - accuracy: 0.9524 - val_loss: 0.7136 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(train_x, train_y, verbose=1, batch_size=32, epochs=200, validation_split=0.3)"
   ]
  },
  {
   "source": [
    "There are two graphs below to demonstrate the relationship between accuracy, loss, and our epoch. What trend do you generally notice here? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "QdabkSwphd_n",
    "outputId": "1d93e2ed-08ff-46ab-c86b-11f848c98bef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-feature",
   "metadata": {
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Now, let's see how the model performs on our test data set after the model has been trained. Two values will be returned: the loss of our model (a number which represents our error -- lower values are better), and the accuracy of our model. You can try adjusting the batch size too to see how it affects the model's loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02694994 0.32540676 0.64764327]\n",
      " [0.0573839  0.454274   0.48834205]\n",
      " [0.4494218  0.24518618 0.30539203]\n",
      " [0.01584578 0.36030072 0.62385356]\n",
      " [0.02634715 0.5248358  0.44881704]\n",
      " [0.45135206 0.2415105  0.3071375 ]\n",
      " [0.02668841 0.5560593  0.4172524 ]\n",
      " [0.01033322 0.22954245 0.7601244 ]\n",
      " [0.47128272 0.21292578 0.31579143]\n",
      " [0.45120147 0.24156916 0.3072293 ]\n",
      " [0.03327423 0.45315927 0.5135665 ]\n",
      " [0.04281126 0.33257326 0.6246155 ]\n",
      " [0.01717958 0.3119913  0.6708291 ]\n",
      " [0.42449212 0.27916098 0.29634693]\n",
      " [0.00785492 0.2328579  0.7592872 ]\n",
      " [0.00950476 0.21187212 0.7786231 ]\n",
      " [0.46491107 0.22323282 0.31185606]\n",
      " [0.02139382 0.46161482 0.51699144]\n",
      " [0.02267247 0.27892298 0.6984046 ]\n",
      " [0.466476   0.21252501 0.32099903]\n",
      " [0.45684126 0.23211919 0.31103948]\n",
      " [0.46905023 0.21723962 0.31371012]\n",
      " [0.45091084 0.2436489  0.30544022]\n",
      " [0.4624424  0.22675787 0.31079972]\n",
      " [0.04133173 0.4592095  0.4994588 ]\n",
      " [0.01552469 0.1791857  0.80528957]\n",
      " [0.46736464 0.21975294 0.31288245]\n",
      " [0.0402211  0.44139326 0.51838565]\n",
      " [0.08009986 0.5411588  0.37874132]\n",
      " [0.01215397 0.35789806 0.629948  ]\n",
      " [0.05003449 0.46819767 0.48176783]\n",
      " [0.05445409 0.55818194 0.387364  ]\n",
      " [0.01795127 0.2634572  0.7185916 ]\n",
      " [0.46433708 0.22385263 0.3118103 ]\n",
      " [0.02825541 0.51713806 0.45460653]\n",
      " [0.01078602 0.24233378 0.7468802 ]\n",
      " [0.46462488 0.2234599  0.3119152 ]\n",
      " [0.01359493 0.27762502 0.7087801 ]\n",
      " [0.46612307 0.22103183 0.31284505]\n",
      " [0.46140638 0.21935877 0.31923482]\n",
      " [0.45227346 0.23917323 0.30855334]\n",
      " [0.01010873 0.3313077  0.6585836 ]\n",
      " [0.01025448 0.21471515 0.7750304 ]\n",
      " [0.02498812 0.32933193 0.64567995]\n",
      " [0.00988518 0.18096304 0.8091518 ]\n",
      " [0.04806441 0.5511023  0.40083328]\n",
      " [0.47402576 0.20833099 0.3176433 ]\n",
      " [0.02017786 0.38156354 0.5982586 ]\n",
      " [0.04542759 0.49070603 0.46386638]\n",
      " [0.45636144 0.23410478 0.3095338 ]\n",
      " [0.01603367 0.2524294  0.7315369 ]\n",
      " [0.45554566 0.23585288 0.30860147]\n",
      " [0.05331766 0.5566824  0.38999993]\n",
      " [0.48578364 0.1925124  0.32170397]\n",
      " [0.46138152 0.22783102 0.3107875 ]\n",
      " [0.45372227 0.2396251  0.30665255]\n",
      " [0.46906856 0.21717556 0.3137559 ]\n",
      " [0.4317595  0.24267578 0.3255647 ]\n",
      " [0.45815524 0.23306611 0.3087786 ]\n",
      " [0.47319165 0.2110814  0.31572694]\n",
      " [0.01631931 0.3219591  0.6617216 ]\n",
      " [0.04141733 0.36349624 0.5950864 ]\n",
      " [0.02139728 0.35645023 0.6221525 ]\n",
      " [0.0100371  0.21310906 0.77685386]\n",
      " [0.04945843 0.48805004 0.46249148]\n",
      " [0.46988437 0.2144527  0.3156629 ]\n",
      " [0.02056495 0.3101121  0.6693229 ]\n",
      " [0.04531408 0.46784392 0.48684195]\n",
      " [0.46077064 0.22626929 0.31296006]\n",
      " [0.04142886 0.5666615  0.39190966]\n",
      " [0.05541119 0.5696576  0.37493116]\n",
      " [0.44318584 0.24948952 0.30732465]\n",
      " [0.00839503 0.12205157 0.86955345]\n",
      " [0.45390484 0.2385234  0.3075718 ]\n",
      " [0.03657853 0.4079393  0.55548215]\n",
      " [0.06895103 0.51758856 0.4134604 ]\n",
      " [0.00334957 0.22954115 0.76710933]\n",
      " [0.01484442 0.28827798 0.6968776 ]\n",
      " [0.014225   0.32059225 0.66518277]\n",
      " [0.42069045 0.2582268  0.32108265]\n",
      " [0.03071573 0.2975317  0.6717526 ]\n",
      " [0.02314684 0.37029758 0.6065556 ]\n",
      " [0.4510083  0.24259593 0.30639577]\n",
      " [0.01073951 0.33317238 0.6560882 ]\n",
      " [0.46527806 0.22167684 0.31304505]\n",
      " [0.0944054  0.5282532  0.37734145]\n",
      " [0.02050239 0.23285048 0.7466472 ]\n",
      " [0.0335212  0.57233125 0.39414752]\n",
      " [0.45840532 0.23103513 0.3105596 ]\n",
      " [0.04794795 0.56163055 0.39042142]\n",
      " [0.01297197 0.17247207 0.814556  ]\n",
      " [0.01858496 0.40399504 0.57742   ]\n",
      " [0.45814633 0.22146569 0.32038805]\n",
      " [0.4501093  0.23379405 0.3160966 ]\n",
      " [0.04593429 0.44701952 0.5070462 ]\n",
      " [0.01795126 0.26345715 0.7185916 ]\n",
      " [0.03597946 0.4364658  0.5275548 ]\n",
      " [0.03730506 0.5603513  0.4023436 ]\n",
      " [0.03937606 0.48006704 0.48055696]\n",
      " [0.00852414 0.34427357 0.6472023 ]\n",
      " [0.03733654 0.45723456 0.5054289 ]\n",
      " [0.05579751 0.4828949  0.46130756]\n",
      " [0.07978943 0.5536636  0.366547  ]\n",
      " [0.07687336 0.5586387  0.36448795]\n",
      " [0.01351887 0.24903566 0.73744553]\n",
      " [0.01237581 0.1598612  0.82776296]\n",
      " [0.45909628 0.23213628 0.3087675 ]\n",
      " [0.02396913 0.50150615 0.47452474]\n",
      " [0.452575   0.24093917 0.30648586]\n",
      " [0.0343409  0.5634771  0.40218198]\n",
      " [0.06049218 0.5591068  0.38040096]\n",
      " [0.01468549 0.21868671 0.7666277 ]\n",
      " [0.45297578 0.23955101 0.30747327]\n",
      " [0.00579193 0.28845584 0.7057522 ]\n",
      " [0.0127705  0.30112895 0.6861006 ]\n",
      " [0.03884657 0.5679902  0.39316335]\n",
      " [0.01366569 0.44154987 0.5447844 ]\n",
      " [0.00675081 0.32226476 0.6709844 ]\n",
      " [0.00530501 0.30407318 0.69062173]\n",
      " [0.46000072 0.23023064 0.30976868]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   Iris-setosa       1.00      1.00      1.00        41\n",
      "Iris-versicolo       1.00      0.59      0.74        39\n",
      "Iris-virginica       0.71      1.00      0.83        40\n",
      "\n",
      "      accuracy                           0.87       120\n",
      "     macro avg       0.90      0.86      0.86       120\n",
      "  weighted avg       0.90      0.87      0.86       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# make a prediction\n",
    "testingPredictions = model.predict(test_x)\n",
    "testingPredictions = list(testingPredictions.argmax(axis=-1))\n",
    "\n",
    "confidence_scores = model.predict(test_x, batch_size=32)\n",
    "print(confidence_scores)\n",
    "\n",
    "target_names = ['Iris-setosa', 'Iris-versicolo', 'Iris-virginica']\n",
    "print(classification_report(test_y.argmax(axis=-1), testingPredictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6181 - accuracy: 0.8667\n",
      "loss: 0.618\n",
      "accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_y, verbose=1)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "source": [
    "Now, we need to export the data in order to support some interactive visualizations that we've created. Feel free to skip over this code block and move to the interactive visualizations below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "oO_hbdmkh-e4",
    "outputId": "58ea8214-b86e-4baf-d2ec-b1f8366af5b4"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_y' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8171e40fc289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_y' is not defined"
     ]
    }
   ],
   "source": [
    "# output data as json \n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_directory = \"libraries/\"\n",
    "output_filename = \"predict_nn.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "true_label = []\n",
    "for i in range(len(test_y)):\n",
    "    for j in range(len(test_y[i])):\n",
    "        if test_y[i][j] == 1:\n",
    "            if j == 0:\n",
    "                true_label.append(target_names[0])\n",
    "            if j == 1:\n",
    "                true_label.append(target_names[1])\n",
    "            if j == 2:\n",
    "                true_label.append(target_names[2])\n",
    "\n",
    "\n",
    "for i in range(len(testingPredictions)):\n",
    "    if testingPredictions[i] == 0:\n",
    "        testingPredictions[i] = target_names[0]\n",
    "    if testingPredictions[i] == 1:\n",
    "        testingPredictions[i] = target_names[1]\n",
    "    if testingPredictions[i] == 2:\n",
    "        testingPredictions[i] = target_names[2]\n",
    "\n",
    "data = []\n",
    "data.extend([{\n",
    "      'index': i,\n",
    "      'true_label': true_label[i],\n",
    "      'predicted_label': testingPredictions[i],\n",
    "      'confidence_score': confidence_scores.tolist()[i],\n",
    "      'features': test_x.tolist()[i]\n",
    "  } for i in range(len(testingPredictions))])\n",
    "\n",
    "\n",
    "\n",
    "with open(full_path, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import libraries.mlvislib as mlvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'full_path' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-06cdf0142471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_path' is not defined"
     ]
    }
   ],
   "source": [
    "cm = mlvs.ConfusionMatrix(full_path)\n",
    "cm.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}