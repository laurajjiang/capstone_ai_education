{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Convolutional Neural Network for Image Classification \n",
    "\n",
    "In this notebook, we'll learn how to create a convolutional neural network for multi-categorical image classification using the FashionMNIST dataset. Almost all of this notebook will look identical to the previous chapter on a non-convlutional neural network except for the new model being introduced. Because of this, we won't spend as much time explaining the identical code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UTxod1Igo_32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script data-require=\"d3@3.5.3\" data-semver=\"3.5.3\" src=\"//cdnjs.cloudflare.com/ajax/libs/d3/3.5.3/d3.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from IPython.core.display import HTML, display\n",
    "# Initializing D3 for the entire notebook (this fixes error requiring kernel to load twice)\n",
    "# (feel free to move this line to anywhere in notebook before visualizations)\n",
    "display(HTML('<script data-require=\"d3@3.5.3\" data-semver=\"3.5.3\" src=\"//cdnjs.cloudflare.com/ajax/libs/d3/3.5.3/d3.js\"></script>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data \n",
    "\n",
    "We utilize the built in training/test set split and reshape our images to be identical vectors. Afterwards, we normalize the image RGB values between 0 and 1. Lastly, we encode our labels to be binary 0 or 1 corresponding to their respective category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74gmT-MKpTOT",
    "outputId": "9b8e3fc0-9015-4ad1-8fac-29b3c7887820"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# 60,000 training images, 10,000 test images\n",
    "(training_imgs, training_labels), (test_imgs, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AEkXyLfGvk4x"
   },
   "outputs": [],
   "source": [
    "training_imgs = training_imgs.reshape((training_imgs.shape[0], 28, 28, 1))\n",
    "training_imgs = training_imgs/255.0\n",
    "test_imgs = test_imgs/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GEHeShVBy-gV"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_imgs = test_imgs.reshape((test_imgs.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gNJZuLzmvmU9"
   },
   "outputs": [],
   "source": [
    "encoder1 = OneHotEncoder(sparse=False)\n",
    "encoder2 = OneHotEncoder(sparse=False)\n",
    "training_labels = training_labels.reshape(-1, 1)\n",
    "test_labels = test_labels.reshape(-1, 1)\n",
    "training_labels = encoder1.fit_transform(training_labels)\n",
    "test_labels = encoder2.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our model\n",
    "\n",
    "This neural network looks quite different from our previous model, although many factors do stay the same. You'll notice that there are two new elements: a convolutional layer (Conv2D) and a max pooling layer (MaxPooling2D). \n",
    "\n",
    "Looking at the model summary, you can start to piece together what each of these layers accomplish. \n",
    "\n",
    "A convolutional layer applies a filter to an image to build a new image by applying that filter. This helps us extract relevant information from a picture and discard any information that is not relevant to our image classification problem.\n",
    "\n",
    "`tf.keras.layers.Conv2D(32, (3,3), activation='relu',  input_shape=(28,28,1))` translates to: apply 32 output filters in our convolution, use a `3x3` convolution window, a `ReLU` activation function, and use our images with an input of `28x28` pixels. \n",
    "\n",
    "A max pooling layer works to reduce the dimensions (pixels) of our input images. With a filter size of `2x2`, and a default stride of 2 (stride affects how many pixels are skipped over when our filter looks at an input image), our output dimensions will be cut in half `(None, 26, 26, 32)` to  `(None, 13, 13, 32)`. We keep the results from our filtered image and perhaps enhance relevant details. Because of this, max pooling is useful to simplify computation and reduce overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_SwMNVdZrjDC"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu',  input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDIgGI2_tkU1",
    "outputId": "a3015428-678a-4938-9778-e6baaae6b7b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 113,386\n",
      "Trainable params: 113,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model \n",
    "\n",
    "Now we can train our model. How does this convolutional model compare to the standard neural network model that we creatd in the previous chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing callback data extractor\n",
    "import os, sys\n",
    "import libraries.extractioncallback as excb\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "extractor = excb.CallbackDataExtractor(\n",
    "    model = model,\n",
    "    layer = 1,\n",
    "    validation_data = (test_imgs, test_labels),\n",
    "    sample_every = 1,\n",
    "    rec_int_values = False,\n",
    "    is_bin = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlpGOkmqtiUM",
    "outputId": "f2f3d455-45ab-415d-d8af-813414ca9d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 11s 8ms/step - loss: 0.9979 - accuracy: 0.6470 - val_loss: 0.6986 - val_accuracy: 0.7455\n",
      "Collecting data on epoch  0 ...\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 10s 8ms/step - loss: 0.6001 - accuracy: 0.7737 - val_loss: 0.5864 - val_accuracy: 0.7867\n",
      "Collecting data on epoch  1 ...\n",
      "Epoch 3/10\n",
      "1313/1313 [==============================] - 10s 8ms/step - loss: 0.5149 - accuracy: 0.8088 - val_loss: 0.5622 - val_accuracy: 0.7627\n",
      "Collecting data on epoch  2 ...\n",
      "Epoch 4/10\n",
      "1313/1313 [==============================] - 11s 8ms/step - loss: 0.4676 - accuracy: 0.8280 - val_loss: 0.5175 - val_accuracy: 0.8058\n",
      "Collecting data on epoch  3 ...\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - 11s 8ms/step - loss: 0.4345 - accuracy: 0.8418 - val_loss: 0.4478 - val_accuracy: 0.8343\n",
      "Collecting data on epoch  4 ...\n",
      "Epoch 6/10\n",
      "1313/1313 [==============================] - 10s 8ms/step - loss: 0.4099 - accuracy: 0.8520 - val_loss: 0.4154 - val_accuracy: 0.8502\n",
      "Collecting data on epoch  5 ...\n",
      "Epoch 7/10\n",
      "1313/1313 [==============================] - 10s 8ms/step - loss: 0.3887 - accuracy: 0.8600 - val_loss: 0.4038 - val_accuracy: 0.8482\n",
      "Collecting data on epoch  6 ...\n",
      "Epoch 8/10\n",
      "1313/1313 [==============================] - 11s 8ms/step - loss: 0.3718 - accuracy: 0.8655 - val_loss: 0.3819 - val_accuracy: 0.8620\n",
      "Collecting data on epoch  7 ...\n",
      "Epoch 9/10\n",
      "1307/1313 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.8704"
     ]
    }
   ],
   "source": [
    "hist = model.fit(training_imgs, training_labels, verbose=1, epochs=10, validation_split=0.3, callbacks=[extractor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the model's accuracy and loss per epoch below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "0CE8JuJ6tico",
    "outputId": "bba27444-6ed7-4ff3-9665-f1455710eddb"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our model\n",
    "\n",
    "The process for evaluating our model follows from previous notebooks. We will see the model's confidence score in its predictions on the test set, print a classification report, then plot a few results from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "eC6eowlewbfA",
    "outputId": "a1f5455e-6024-4a3b-fe3b-9199c7150c60"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "testingPredictions = model.predict(test_imgs)\n",
    "testingPredictions = list(testingPredictions.argmax(axis=-1))\n",
    "confidence_scores = model.predict(test_imgs, batch_size=32)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(confidence_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(classification_report(test_labels.argmax(axis=-1), testingPredictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, confidence_scores, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "\n",
    "  #predicted_label = np.argmax(predictions_array)\n",
    "  #print(predicted_label, true_label)\n",
    "  if predictions_array[i] == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(target_names[predictions_array[i]],\n",
    "                                100*np.max(confidence_scores[i]),\n",
    "                                target_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 3\n",
    "num_cols = 5\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "vec = np.vectorize(confidence_scores)\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, testingPredictions, confidence_scores, test_labels.argmax(axis=-1), test_imgs)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, list(confidence_scores)[i], test_labels.argmax(axis=-1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to export the data in order to support some interactive visualizations that we've created. Feel free to skip over this code block and move to the interactive visualizations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "\n",
    "output_directory = \"libraries/stored_results\"\n",
    "output_filename = \"c_neural_network_img.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "epoch_output = extractor.get_testing_results()\n",
    "extractor.generateJSON(num_entries=2000, path=full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libraries.mlvislib as mlvs\n",
    "cm = mlvs.ConfusionMatrix(full_path, x_labels=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
    "                          y_labels=[\"9\", \"8\", \"7\", \"6\", \"7\", \"6\", \"5\", \"4\", \"3\", \"2\", \"1\", \"0\"])\n",
    "cm.display()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "c_neural_network_img",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
