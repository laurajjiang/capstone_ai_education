{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "burning-clinic",
   "metadata": {
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "## Creating a Logistic Regression Model\n",
    "\n",
    "Logistic Regression is classification algorithm commonly used in machine learning. It allows us to categorize data into discrete classes (binary categories) by learning the relationship from a given set of labeled data. A logistic regression model learns a linear relationship from the given dataset and then introduces a non-linearity in the form of the Sigmoid function, described below, to return a probability value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bulgarian-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "def sigmoid(z): \n",
    "    return 1 / (1 + np.exp( - z)) \n",
    "  \n",
    "plt.plot(np.arange(-5, 5, 0.1), sigmoid(np.arange(-5, 5, 0.1))) \n",
    "plt.title('Visualization of the Sigmoid Function') \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-transaction",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "The Iris flower dataset is available on [Keras Dataset API](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html). \n",
    "\n",
    "The following code loads the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# import iris data from sklearn datasets library\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "introductory-dining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     target  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "..      ...  \n",
      "145       2  \n",
      "146       2  \n",
      "147       2  \n",
      "148       2  \n",
      "149       2  \n",
      "\n",
      "[150 rows x 5 columns]\n",
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# To use tenforflow 1.x functions, import compact v1\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.enable_eager_execution()\n",
    "# # # make unable to use tensorflow v2.x functions to avoid crash\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# change to pandas dataframe\n",
    "iris = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "iris = iris.astype({\"target\": int })\n",
    "\n",
    "print(iris)\n",
    "print(iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-premiere",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## Explore the data \n",
    "\n",
    "Let's take a moment to understand the format of the data. Each data contains sepal length, sepal width, petal length, petal width and a corresponding species label. The label is an integer value of either 0 or 1, where 0 is a `Iris-setosa`, and 1 is a `Iris-versicolo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coated-excerpt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the head of dataframe\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "representative-regard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa4980bb160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a scatter plot with sepal length and width between two iris species in the dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(iris['sepal length (cm)'][:50], iris['sepal width (cm)'][:50], label='Iris-setosa')\n",
    "plt.scatter(iris['sepal length (cm)'][51:], iris['sepal width (cm)'][51:], label='Iris-versicolo')\n",
    "# plt.scatter(iris['sepal length (cm)'][101:], iris['sepal width (cm)'][101:], label='Iris-virginica')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-replication",
   "metadata": {
    "id": "h5bmxzE0Fobd"
   },
   "source": [
    "## Processing Data\n",
    "\n",
    "We need to process our data to split the overall dataset into a training set and a test set.\n",
    "\n",
    "The x-value from our dataset will become the features (sepal length, sepal width, petal length, petal width) and y value as species (labels -- `Iris-setosa` or `Iris-versicolo`) from the Iris dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ordinary-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop(labels=['target'], axis=1).values\n",
    "y = iris['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-algorithm",
   "metadata": {},
   "source": [
    "Set a seed to get reproducibility for numpy and tensorflow so for the next step, our training and test dataset are split the same way each time you run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "protected-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-passion",
   "metadata": {},
   "source": [
    "Next, we split the dataset into a training set (60%, used to train our model and familiarize the model with the kind of data it will be classifying) and a test set (40%, evaluate the model and how effective it is as classifying new, unseen before data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "changed-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random choice from numpy library to set dataset randomly\n",
    "train_data = np.random.choice(len(x), round(len(x) * 0.6), replace=False)\n",
    "test_data = np.array(list(set(range(len(x))) - set(train_data)))\n",
    "\n",
    "# separate the dataset into features and labels\n",
    "x_train = x[train_data]\n",
    "y_train = y[train_data]\n",
    "x_test = x[test_data]\n",
    "y_test = y[test_data]\n",
    "\n",
    "# the number of labels\n",
    "num_labels = 3 \n",
    "\n",
    "# the number of features: sepal length & width, petal length & width\n",
    "num_features = 4\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-submission",
   "metadata": {},
   "source": [
    "Now, we normalize the feature values in the dataset. Normalization is optional for logistic regression, however, the main goal of normalizing features is to help the convergence of the technique used for optimization. \n",
    "\n",
    "(TODO: explain a bit more about normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confidential-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalization function\n",
    "def min_max_normalization(data):\n",
    "    col_max = np.max(data, axis=0)\n",
    "    col_min = np.min(data, axis=0)\n",
    "    return np.divide(data - col_min, col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "original-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized processing, must be placed after the data set segmentation, \n",
    "# otherwise the test set will be affected by the training set\n",
    "x_train = min_max_normalization(x_train)\n",
    "x_test = min_max_normalization(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "considered-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make y dataset shape to fit on model dimensions as multi-class classification\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adopted-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-helicopter",
   "metadata": {
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "With the processed dataset, we can now start to build the model with Tensorflow and Keras. You'll notice that our model has an activation function, which defines the output range of our model. As mentioned, we will be using the Sigmoid function as our activation function to normalize our output between 0 and 1. \n",
    "\n",
    "There are a few other activation functions that you can try out and see how they affect the model. Learn about more activation functions through the [Keras documentation](https://keras.io/api/layers/activations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sitting-april",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "# Set up the logistic regression model\n",
    "model = Sequential()\n",
    "# the number of class, Iris dataset has 3 classes\n",
    "output_dim = num_labels\n",
    "# input dimension = number of features your data has\n",
    "input_dim = num_features\n",
    "\n",
    "model.add(Dense(output_dim,\n",
    "                input_dim = input_dim,\n",
    "                activation='sigmoid'\n",
    "                )) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-spanish",
   "metadata": {},
   "source": [
    "Before training our model, we also need to set a few parameters: learning rate, batch size, and the number of epoch interations.\n",
    "* <b>Learning rate</b> is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient.\n",
    "* <b>Batch size</b> defines the number of samples that will be propagated through the network.\n",
    "* An <b>epoch</b> is a full iteration over our samples during model training. \n",
    "\n",
    "Feel free to adjust these parameters, especially the learning rate and number of epochs. How do they change the model's accuracy and loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "furnished-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "batch_size = 32\n",
    "epochs_num = 500"
   ]
  },
  {
   "attachments": {
    "log_loss.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "corresponding-invite",
   "metadata": {},
   "source": [
    "### Loss function and optimizer\n",
    "\n",
    "Here, we declare a loss function for our linear regression. Why does we need one?\n",
    "\n",
    "The loss function is critical for machine & deep learning models.\n",
    "The loss function for linear regression is squared loss, but the loss function for logistic regression is Log Loss, which is defined as follows:\n",
    "\n",
    "![log_loss.PNG](attachment:log_loss.PNG)\n",
    "\n",
    "where:\n",
    "\n",
    "* (x,y) ∈ D is the data set containing many labeled examples, which are  (x,y) pairs.\n",
    "* y is the label in a labeled example. Since this is logistic regression, every value of y must either be 0 or 1.\n",
    "* y' is the predicted value (somewhere between 0 and 1), given the set of features in x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thirty-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Setup Callback function\n",
    "# Requires: model and validation_data (X and Y values of test data)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "\n",
    "# confusion_matrix_updates = ConfMatrixCallbackPlotter(\n",
    "#                                 model = model,\n",
    "#                                 scaler = scaler,\n",
    "#                                 validation_data = (x_test, y_test),\n",
    "#                                 original_input = x_test)\n",
    "\n",
    "import libraries.extractioncallback as excb\n",
    "\n",
    "extractor = excb.CallbackDataExtractor(\n",
    "    model = model,\n",
    "    layer = 0,\n",
    "    validation_data = (x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-desert",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We can start to train our model. We use the parameters that we set above. The `validation_split` parameter selects what fraction of our training data will be held as validation data, used to evaluate model metrics per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "living-movement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0547 - accuracy: 0.3196 - val_loss: 1.0380 - val_accuracy: 0.3929\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0531 - accuracy: 0.3300 - val_loss: 1.0345 - val_accuracy: 0.3929\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0569 - accuracy: 0.3196 - val_loss: 1.0311 - val_accuracy: 0.3929\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0383 - accuracy: 0.3404 - val_loss: 1.0277 - val_accuracy: 0.3929\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0448 - accuracy: 0.3091 - val_loss: 1.0244 - val_accuracy: 0.3929\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0182 - accuracy: 0.3300 - val_loss: 1.0212 - val_accuracy: 0.3929\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0296 - accuracy: 0.3300 - val_loss: 1.0180 - val_accuracy: 0.3929\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0078 - accuracy: 0.3508 - val_loss: 1.0149 - val_accuracy: 0.4286\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.9936 - accuracy: 0.3824 - val_loss: 1.0118 - val_accuracy: 0.4643\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.9995 - accuracy: 0.4257 - val_loss: 1.0088 - val_accuracy: 0.4643\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.9857 - accuracy: 0.4573 - val_loss: 1.0058 - val_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0005 - accuracy: 0.4788 - val_loss: 1.0029 - val_accuracy: 0.5357\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9924 - accuracy: 0.5215 - val_loss: 1.0000 - val_accuracy: 0.5357\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9804 - accuracy: 0.5743 - val_loss: 0.9972 - val_accuracy: 0.5357\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9750 - accuracy: 0.6277 - val_loss: 0.9944 - val_accuracy: 0.5714\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9730 - accuracy: 0.6489 - val_loss: 0.9916 - val_accuracy: 0.6071\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.9699 - accuracy: 0.6489 - val_loss: 0.9889 - val_accuracy: 0.6429\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9730 - accuracy: 0.7120 - val_loss: 0.9861 - val_accuracy: 0.6429\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9738 - accuracy: 0.6808 - val_loss: 0.9835 - val_accuracy: 0.6429\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.9672 - accuracy: 0.6704 - val_loss: 0.9808 - val_accuracy: 0.6429\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9586 - accuracy: 0.7019 - val_loss: 0.9782 - val_accuracy: 0.6429\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9895 - accuracy: 0.6915 - val_loss: 0.9756 - val_accuracy: 0.6429\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9709 - accuracy: 0.6915 - val_loss: 0.9731 - val_accuracy: 0.6429\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9669 - accuracy: 0.6915 - val_loss: 0.9705 - val_accuracy: 0.6429\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9486 - accuracy: 0.6915 - val_loss: 0.9680 - val_accuracy: 0.6429\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9574 - accuracy: 0.7019 - val_loss: 0.9655 - val_accuracy: 0.6429\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9580 - accuracy: 0.6915 - val_loss: 0.9630 - val_accuracy: 0.6429\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9371 - accuracy: 0.7019 - val_loss: 0.9606 - val_accuracy: 0.6429\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9175 - accuracy: 0.7332 - val_loss: 0.9582 - val_accuracy: 0.6429\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.9537 - accuracy: 0.6499 - val_loss: 0.9558 - val_accuracy: 0.6429\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9264 - accuracy: 0.7124 - val_loss: 0.9534 - val_accuracy: 0.6429\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9299 - accuracy: 0.6915 - val_loss: 0.9511 - val_accuracy: 0.6429\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.9450 - accuracy: 0.6811 - val_loss: 0.9487 - val_accuracy: 0.6429\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.9177 - accuracy: 0.7332 - val_loss: 0.9464 - val_accuracy: 0.6429\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9181 - accuracy: 0.7124 - val_loss: 0.9441 - val_accuracy: 0.6429\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.9107 - accuracy: 0.7124 - val_loss: 0.9418 - val_accuracy: 0.6429\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9166 - accuracy: 0.7019 - val_loss: 0.9395 - val_accuracy: 0.6429\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.9245 - accuracy: 0.6915 - val_loss: 0.9373 - val_accuracy: 0.6429\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.9224 - accuracy: 0.6811 - val_loss: 0.9350 - val_accuracy: 0.6429\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8867 - accuracy: 0.7540 - val_loss: 0.9328 - val_accuracy: 0.6429\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9165 - accuracy: 0.6811 - val_loss: 0.9306 - val_accuracy: 0.6429\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9136 - accuracy: 0.6919 - val_loss: 0.9284 - val_accuracy: 0.6429\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8979 - accuracy: 0.7019 - val_loss: 0.9263 - val_accuracy: 0.6429\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8886 - accuracy: 0.7228 - val_loss: 0.9241 - val_accuracy: 0.6429\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8944 - accuracy: 0.7019 - val_loss: 0.9220 - val_accuracy: 0.6429\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8726 - accuracy: 0.7332 - val_loss: 0.9199 - val_accuracy: 0.6429\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9035 - accuracy: 0.6915 - val_loss: 0.9178 - val_accuracy: 0.6429\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8833 - accuracy: 0.7124 - val_loss: 0.9157 - val_accuracy: 0.6429\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8928 - accuracy: 0.6915 - val_loss: 0.9136 - val_accuracy: 0.6429\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8780 - accuracy: 0.7019 - val_loss: 0.9115 - val_accuracy: 0.6429\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8777 - accuracy: 0.7124 - val_loss: 0.9095 - val_accuracy: 0.6429\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8896 - accuracy: 0.6707 - val_loss: 0.9074 - val_accuracy: 0.6429\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8786 - accuracy: 0.6915 - val_loss: 0.9054 - val_accuracy: 0.6429\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.8827 - accuracy: 0.6707 - val_loss: 0.9034 - val_accuracy: 0.6429\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.8687 - accuracy: 0.6915 - val_loss: 0.9014 - val_accuracy: 0.6429\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8805 - accuracy: 0.6811 - val_loss: 0.8994 - val_accuracy: 0.6429\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8702 - accuracy: 0.6915 - val_loss: 0.8975 - val_accuracy: 0.6429\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8765 - accuracy: 0.6603 - val_loss: 0.8955 - val_accuracy: 0.6429\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 0.8600 - accuracy: 0.7019 - val_loss: 0.8936 - val_accuracy: 0.6429\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8687 - accuracy: 0.6915 - val_loss: 0.8917 - val_accuracy: 0.6429\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8606 - accuracy: 0.6915 - val_loss: 0.8897 - val_accuracy: 0.6429\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8430 - accuracy: 0.7332 - val_loss: 0.8878 - val_accuracy: 0.6429\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8504 - accuracy: 0.7124 - val_loss: 0.8859 - val_accuracy: 0.6429\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.8662 - accuracy: 0.6707 - val_loss: 0.8840 - val_accuracy: 0.6429\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8501 - accuracy: 0.6811 - val_loss: 0.8822 - val_accuracy: 0.6429\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8441 - accuracy: 0.6915 - val_loss: 0.8803 - val_accuracy: 0.6429\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8476 - accuracy: 0.7127 - val_loss: 0.8785 - val_accuracy: 0.6429\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8589 - accuracy: 0.6815 - val_loss: 0.8767 - val_accuracy: 0.6429\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8510 - accuracy: 0.6919 - val_loss: 0.8748 - val_accuracy: 0.6429\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8435 - accuracy: 0.7231 - val_loss: 0.8730 - val_accuracy: 0.6429\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8406 - accuracy: 0.7023 - val_loss: 0.8712 - val_accuracy: 0.6429\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8330 - accuracy: 0.7231 - val_loss: 0.8695 - val_accuracy: 0.6429\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.8305 - accuracy: 0.7231 - val_loss: 0.8677 - val_accuracy: 0.6429\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8416 - accuracy: 0.6919 - val_loss: 0.8659 - val_accuracy: 0.6429\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8324 - accuracy: 0.7023 - val_loss: 0.8641 - val_accuracy: 0.6429\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8221 - accuracy: 0.7231 - val_loss: 0.8624 - val_accuracy: 0.6429\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8253 - accuracy: 0.7231 - val_loss: 0.8607 - val_accuracy: 0.6429\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8114 - accuracy: 0.7335 - val_loss: 0.8589 - val_accuracy: 0.6429\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8346 - accuracy: 0.6919 - val_loss: 0.8572 - val_accuracy: 0.6429\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.8183 - accuracy: 0.7231 - val_loss: 0.8555 - val_accuracy: 0.6429\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8225 - accuracy: 0.7023 - val_loss: 0.8538 - val_accuracy: 0.6429\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8199 - accuracy: 0.7023 - val_loss: 0.8522 - val_accuracy: 0.6429\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8184 - accuracy: 0.7023 - val_loss: 0.8505 - val_accuracy: 0.6429\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8167 - accuracy: 0.7023 - val_loss: 0.8488 - val_accuracy: 0.6429\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7979 - accuracy: 0.7231 - val_loss: 0.8472 - val_accuracy: 0.6429\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8174 - accuracy: 0.6919 - val_loss: 0.8455 - val_accuracy: 0.6429\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8199 - accuracy: 0.6815 - val_loss: 0.8439 - val_accuracy: 0.6429\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.8084 - accuracy: 0.7127 - val_loss: 0.8423 - val_accuracy: 0.6429\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8076 - accuracy: 0.7023 - val_loss: 0.8407 - val_accuracy: 0.6429\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7979 - accuracy: 0.7231 - val_loss: 0.8391 - val_accuracy: 0.6429\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7862 - accuracy: 0.7127 - val_loss: 0.8375 - val_accuracy: 0.6429\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7788 - accuracy: 0.7440 - val_loss: 0.8359 - val_accuracy: 0.6429\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8064 - accuracy: 0.6919 - val_loss: 0.8343 - val_accuracy: 0.6429\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8050 - accuracy: 0.6815 - val_loss: 0.8328 - val_accuracy: 0.6429\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7937 - accuracy: 0.7023 - val_loss: 0.8312 - val_accuracy: 0.6429\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8042 - accuracy: 0.6815 - val_loss: 0.8297 - val_accuracy: 0.6429\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8023 - accuracy: 0.6919 - val_loss: 0.8281 - val_accuracy: 0.6429\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7842 - accuracy: 0.7231 - val_loss: 0.8266 - val_accuracy: 0.6429\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7763 - accuracy: 0.7231 - val_loss: 0.8251 - val_accuracy: 0.6429\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7804 - accuracy: 0.7127 - val_loss: 0.8236 - val_accuracy: 0.6429\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7576 - accuracy: 0.7440 - val_loss: 0.8221 - val_accuracy: 0.6429\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7963 - accuracy: 0.6815 - val_loss: 0.8206 - val_accuracy: 0.6429\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7793 - accuracy: 0.7023 - val_loss: 0.8192 - val_accuracy: 0.6429\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7749 - accuracy: 0.7231 - val_loss: 0.8177 - val_accuracy: 0.6429\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7569 - accuracy: 0.7440 - val_loss: 0.8162 - val_accuracy: 0.6429\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7862 - accuracy: 0.7023 - val_loss: 0.8148 - val_accuracy: 0.6429\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7655 - accuracy: 0.7023 - val_loss: 0.8133 - val_accuracy: 0.6429\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7763 - accuracy: 0.6919 - val_loss: 0.8119 - val_accuracy: 0.6429\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7830 - accuracy: 0.7023 - val_loss: 0.8104 - val_accuracy: 0.6429\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7534 - accuracy: 0.7231 - val_loss: 0.8090 - val_accuracy: 0.6429\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7834 - accuracy: 0.6815 - val_loss: 0.8076 - val_accuracy: 0.6429\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7547 - accuracy: 0.7127 - val_loss: 0.8062 - val_accuracy: 0.6429\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7650 - accuracy: 0.7023 - val_loss: 0.8048 - val_accuracy: 0.6429\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7744 - accuracy: 0.6815 - val_loss: 0.8034 - val_accuracy: 0.6429\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7647 - accuracy: 0.7023 - val_loss: 0.8020 - val_accuracy: 0.6429\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7592 - accuracy: 0.7127 - val_loss: 0.8007 - val_accuracy: 0.6429\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7539 - accuracy: 0.7127 - val_loss: 0.7993 - val_accuracy: 0.6429\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7593 - accuracy: 0.7023 - val_loss: 0.7979 - val_accuracy: 0.6429\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7484 - accuracy: 0.7231 - val_loss: 0.7966 - val_accuracy: 0.6429\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7490 - accuracy: 0.7231 - val_loss: 0.7952 - val_accuracy: 0.6429\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7664 - accuracy: 0.6815 - val_loss: 0.7939 - val_accuracy: 0.6429\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7699 - accuracy: 0.6815 - val_loss: 0.7926 - val_accuracy: 0.6429\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7515 - accuracy: 0.7023 - val_loss: 0.7913 - val_accuracy: 0.6429\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7468 - accuracy: 0.7023 - val_loss: 0.7900 - val_accuracy: 0.6429\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7325 - accuracy: 0.7440 - val_loss: 0.7887 - val_accuracy: 0.6429\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7362 - accuracy: 0.7127 - val_loss: 0.7874 - val_accuracy: 0.6429\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7499 - accuracy: 0.6919 - val_loss: 0.7861 - val_accuracy: 0.6429\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7359 - accuracy: 0.7231 - val_loss: 0.7848 - val_accuracy: 0.6429\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7491 - accuracy: 0.7026 - val_loss: 0.7835 - val_accuracy: 0.6429\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7656 - accuracy: 0.6710 - val_loss: 0.7823 - val_accuracy: 0.6429\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7315 - accuracy: 0.7231 - val_loss: 0.7810 - val_accuracy: 0.6429\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7381 - accuracy: 0.7023 - val_loss: 0.7798 - val_accuracy: 0.6429\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7200 - accuracy: 0.7547 - val_loss: 0.7785 - val_accuracy: 0.6429\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7287 - accuracy: 0.7127 - val_loss: 0.7773 - val_accuracy: 0.6429\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7324 - accuracy: 0.7339 - val_loss: 0.7761 - val_accuracy: 0.6429\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7336 - accuracy: 0.7235 - val_loss: 0.7748 - val_accuracy: 0.6429\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7107 - accuracy: 0.7547 - val_loss: 0.7736 - val_accuracy: 0.6429\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7360 - accuracy: 0.7130 - val_loss: 0.7724 - val_accuracy: 0.6429\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7147 - accuracy: 0.7339 - val_loss: 0.7712 - val_accuracy: 0.6429\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7277 - accuracy: 0.7235 - val_loss: 0.7700 - val_accuracy: 0.6429\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7313 - accuracy: 0.7130 - val_loss: 0.7688 - val_accuracy: 0.6429\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7198 - accuracy: 0.7235 - val_loss: 0.7676 - val_accuracy: 0.6429\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7276 - accuracy: 0.7235 - val_loss: 0.7665 - val_accuracy: 0.6429\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7220 - accuracy: 0.7339 - val_loss: 0.7653 - val_accuracy: 0.6429\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7246 - accuracy: 0.7026 - val_loss: 0.7641 - val_accuracy: 0.6429\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7231 - accuracy: 0.7342 - val_loss: 0.7630 - val_accuracy: 0.6429\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7038 - accuracy: 0.7550 - val_loss: 0.7618 - val_accuracy: 0.6429\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7035 - accuracy: 0.7759 - val_loss: 0.7607 - val_accuracy: 0.6429\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7257 - accuracy: 0.7241 - val_loss: 0.7595 - val_accuracy: 0.6429\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7339 - accuracy: 0.7134 - val_loss: 0.7584 - val_accuracy: 0.6429\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7015 - accuracy: 0.7443 - val_loss: 0.7572 - val_accuracy: 0.6429\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6978 - accuracy: 0.7342 - val_loss: 0.7561 - val_accuracy: 0.6429\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7143 - accuracy: 0.7550 - val_loss: 0.7550 - val_accuracy: 0.6429\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7278 - accuracy: 0.7030 - val_loss: 0.7539 - val_accuracy: 0.6429\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6880 - accuracy: 0.7759 - val_loss: 0.7528 - val_accuracy: 0.6429\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6900 - accuracy: 0.7655 - val_loss: 0.7517 - val_accuracy: 0.6429\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6951 - accuracy: 0.7554 - val_loss: 0.7506 - val_accuracy: 0.6429\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7076 - accuracy: 0.7342 - val_loss: 0.7495 - val_accuracy: 0.6429\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7167 - accuracy: 0.7450 - val_loss: 0.7484 - val_accuracy: 0.6429\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6673 - accuracy: 0.8075 - val_loss: 0.7474 - val_accuracy: 0.6429\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7089 - accuracy: 0.7450 - val_loss: 0.7463 - val_accuracy: 0.6429\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6870 - accuracy: 0.7554 - val_loss: 0.7452 - val_accuracy: 0.6786\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7130 - accuracy: 0.7345 - val_loss: 0.7442 - val_accuracy: 0.6786\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6896 - accuracy: 0.7554 - val_loss: 0.7431 - val_accuracy: 0.6786\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6902 - accuracy: 0.7450 - val_loss: 0.7421 - val_accuracy: 0.6786\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7060 - accuracy: 0.7345 - val_loss: 0.7410 - val_accuracy: 0.6786\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6852 - accuracy: 0.7658 - val_loss: 0.7400 - val_accuracy: 0.6786\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6881 - accuracy: 0.7450 - val_loss: 0.7390 - val_accuracy: 0.6786\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6796 - accuracy: 0.7658 - val_loss: 0.7379 - val_accuracy: 0.6786\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6830 - accuracy: 0.7762 - val_loss: 0.7369 - val_accuracy: 0.6786\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6748 - accuracy: 0.7554 - val_loss: 0.7359 - val_accuracy: 0.7143\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6796 - accuracy: 0.7554 - val_loss: 0.7349 - val_accuracy: 0.7143\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6681 - accuracy: 0.7762 - val_loss: 0.7339 - val_accuracy: 0.7143\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6747 - accuracy: 0.7870 - val_loss: 0.7329 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6935 - accuracy: 0.7557 - val_loss: 0.7319 - val_accuracy: 0.7143\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6806 - accuracy: 0.7870 - val_loss: 0.7309 - val_accuracy: 0.7143\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6922 - accuracy: 0.7557 - val_loss: 0.7299 - val_accuracy: 0.7143\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6984 - accuracy: 0.7557 - val_loss: 0.7289 - val_accuracy: 0.7143\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6762 - accuracy: 0.7557 - val_loss: 0.7280 - val_accuracy: 0.7143\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6788 - accuracy: 0.7765 - val_loss: 0.7270 - val_accuracy: 0.7143\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6655 - accuracy: 0.7765 - val_loss: 0.7260 - val_accuracy: 0.7143\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6730 - accuracy: 0.7661 - val_loss: 0.7251 - val_accuracy: 0.7143\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6788 - accuracy: 0.7661 - val_loss: 0.7241 - val_accuracy: 0.7143\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6699 - accuracy: 0.7974 - val_loss: 0.7232 - val_accuracy: 0.7143\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6786 - accuracy: 0.7557 - val_loss: 0.7222 - val_accuracy: 0.7143\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6578 - accuracy: 0.7974 - val_loss: 0.7213 - val_accuracy: 0.7143\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6630 - accuracy: 0.7661 - val_loss: 0.7203 - val_accuracy: 0.7143\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6716 - accuracy: 0.7765 - val_loss: 0.7194 - val_accuracy: 0.7500\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6483 - accuracy: 0.8078 - val_loss: 0.7185 - val_accuracy: 0.7500\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6705 - accuracy: 0.7661 - val_loss: 0.7176 - val_accuracy: 0.7500\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6696 - accuracy: 0.7661 - val_loss: 0.7166 - val_accuracy: 0.7500\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6671 - accuracy: 0.7661 - val_loss: 0.7157 - val_accuracy: 0.7500\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6918 - accuracy: 0.7453 - val_loss: 0.7148 - val_accuracy: 0.7500\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6739 - accuracy: 0.7661 - val_loss: 0.7139 - val_accuracy: 0.7500\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6563 - accuracy: 0.7765 - val_loss: 0.7130 - val_accuracy: 0.7500\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6463 - accuracy: 0.7870 - val_loss: 0.7121 - val_accuracy: 0.7500\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6546 - accuracy: 0.7661 - val_loss: 0.7112 - val_accuracy: 0.7500\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6707 - accuracy: 0.7453 - val_loss: 0.7103 - val_accuracy: 0.7500\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6520 - accuracy: 0.7870 - val_loss: 0.7095 - val_accuracy: 0.7500\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6713 - accuracy: 0.7557 - val_loss: 0.7086 - val_accuracy: 0.7500\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6427 - accuracy: 0.7870 - val_loss: 0.7077 - val_accuracy: 0.7500\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6706 - accuracy: 0.7557 - val_loss: 0.7068 - val_accuracy: 0.7500\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6478 - accuracy: 0.7870 - val_loss: 0.7060 - val_accuracy: 0.7500\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6252 - accuracy: 0.7974 - val_loss: 0.7051 - val_accuracy: 0.7500\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6454 - accuracy: 0.7765 - val_loss: 0.7042 - val_accuracy: 0.7500\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6616 - accuracy: 0.7661 - val_loss: 0.7034 - val_accuracy: 0.7500\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6345 - accuracy: 0.7974 - val_loss: 0.7025 - val_accuracy: 0.7500\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6236 - accuracy: 0.7974 - val_loss: 0.7017 - val_accuracy: 0.7500\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6458 - accuracy: 0.7870 - val_loss: 0.7008 - val_accuracy: 0.7500\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6396 - accuracy: 0.7765 - val_loss: 0.7000 - val_accuracy: 0.7500\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6448 - accuracy: 0.7870 - val_loss: 0.6992 - val_accuracy: 0.7500\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6519 - accuracy: 0.7557 - val_loss: 0.6983 - val_accuracy: 0.7500\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6422 - accuracy: 0.7765 - val_loss: 0.6975 - val_accuracy: 0.7500\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6468 - accuracy: 0.7765 - val_loss: 0.6967 - val_accuracy: 0.7500\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6434 - accuracy: 0.7870 - val_loss: 0.6959 - val_accuracy: 0.7500\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6565 - accuracy: 0.7557 - val_loss: 0.6951 - val_accuracy: 0.7500\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6558 - accuracy: 0.7557 - val_loss: 0.6942 - val_accuracy: 0.7500\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6549 - accuracy: 0.7661 - val_loss: 0.6934 - val_accuracy: 0.7500\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6361 - accuracy: 0.7661 - val_loss: 0.6926 - val_accuracy: 0.7500\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6372 - accuracy: 0.7765 - val_loss: 0.6918 - val_accuracy: 0.7500\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6343 - accuracy: 0.7870 - val_loss: 0.6910 - val_accuracy: 0.7500\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6201 - accuracy: 0.8078 - val_loss: 0.6903 - val_accuracy: 0.7500\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6351 - accuracy: 0.7765 - val_loss: 0.6895 - val_accuracy: 0.7500\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6161 - accuracy: 0.7974 - val_loss: 0.6887 - val_accuracy: 0.7500\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6452 - accuracy: 0.7769 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6319 - accuracy: 0.7870 - val_loss: 0.6871 - val_accuracy: 0.7500\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6265 - accuracy: 0.7870 - val_loss: 0.6863 - val_accuracy: 0.7500\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6240 - accuracy: 0.7765 - val_loss: 0.6856 - val_accuracy: 0.7500\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6602 - accuracy: 0.7668 - val_loss: 0.6848 - val_accuracy: 0.7500\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6383 - accuracy: 0.7977 - val_loss: 0.6840 - val_accuracy: 0.7500\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6190 - accuracy: 0.8081 - val_loss: 0.6833 - val_accuracy: 0.7500\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6405 - accuracy: 0.7772 - val_loss: 0.6825 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6331 - accuracy: 0.7981 - val_loss: 0.6818 - val_accuracy: 0.7500\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6431 - accuracy: 0.7876 - val_loss: 0.6810 - val_accuracy: 0.7500\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6373 - accuracy: 0.7873 - val_loss: 0.6803 - val_accuracy: 0.7500\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6201 - accuracy: 0.8293 - val_loss: 0.6795 - val_accuracy: 0.7500\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6254 - accuracy: 0.8189 - val_loss: 0.6788 - val_accuracy: 0.7500\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6148 - accuracy: 0.8189 - val_loss: 0.6780 - val_accuracy: 0.7500\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6077 - accuracy: 0.8397 - val_loss: 0.6773 - val_accuracy: 0.7500\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6574 - accuracy: 0.8088 - val_loss: 0.6766 - val_accuracy: 0.7500\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6299 - accuracy: 0.7984 - val_loss: 0.6759 - val_accuracy: 0.7500\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6057 - accuracy: 0.8401 - val_loss: 0.6751 - val_accuracy: 0.7500\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6227 - accuracy: 0.8192 - val_loss: 0.6744 - val_accuracy: 0.7500\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6213 - accuracy: 0.8296 - val_loss: 0.6737 - val_accuracy: 0.7500\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6167 - accuracy: 0.8296 - val_loss: 0.6730 - val_accuracy: 0.7500\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6214 - accuracy: 0.8296 - val_loss: 0.6722 - val_accuracy: 0.7500\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6210 - accuracy: 0.8192 - val_loss: 0.6715 - val_accuracy: 0.7500\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6055 - accuracy: 0.8401 - val_loss: 0.6708 - val_accuracy: 0.7500\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6277 - accuracy: 0.8296 - val_loss: 0.6701 - val_accuracy: 0.7500\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6400 - accuracy: 0.7880 - val_loss: 0.6694 - val_accuracy: 0.7500\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6232 - accuracy: 0.8088 - val_loss: 0.6687 - val_accuracy: 0.7500\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5959 - accuracy: 0.8296 - val_loss: 0.6680 - val_accuracy: 0.7500\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6356 - accuracy: 0.8088 - val_loss: 0.6673 - val_accuracy: 0.7500\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5926 - accuracy: 0.8505 - val_loss: 0.6666 - val_accuracy: 0.7500\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6325 - accuracy: 0.7984 - val_loss: 0.6659 - val_accuracy: 0.7500\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6063 - accuracy: 0.8296 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6238 - accuracy: 0.8088 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6213 - accuracy: 0.8088 - val_loss: 0.6638 - val_accuracy: 0.7500\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5914 - accuracy: 0.8401 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6123 - accuracy: 0.8296 - val_loss: 0.6625 - val_accuracy: 0.7857\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6110 - accuracy: 0.8088 - val_loss: 0.6618 - val_accuracy: 0.7857\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6093 - accuracy: 0.8296 - val_loss: 0.6612 - val_accuracy: 0.7857\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6023 - accuracy: 0.8401 - val_loss: 0.6605 - val_accuracy: 0.7857\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5989 - accuracy: 0.8401 - val_loss: 0.6598 - val_accuracy: 0.7857\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5973 - accuracy: 0.8401 - val_loss: 0.6592 - val_accuracy: 0.7857\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6068 - accuracy: 0.8088 - val_loss: 0.6585 - val_accuracy: 0.7857\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5831 - accuracy: 0.8401 - val_loss: 0.6579 - val_accuracy: 0.7857\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6026 - accuracy: 0.8401 - val_loss: 0.6572 - val_accuracy: 0.7857\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6115 - accuracy: 0.8192 - val_loss: 0.6565 - val_accuracy: 0.7857\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6140 - accuracy: 0.8192 - val_loss: 0.6559 - val_accuracy: 0.7857\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5960 - accuracy: 0.8401 - val_loss: 0.6552 - val_accuracy: 0.7857\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6079 - accuracy: 0.8401 - val_loss: 0.6546 - val_accuracy: 0.7857\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5941 - accuracy: 0.8296 - val_loss: 0.6540 - val_accuracy: 0.7857\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6077 - accuracy: 0.8296 - val_loss: 0.6533 - val_accuracy: 0.7857\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6017 - accuracy: 0.8296 - val_loss: 0.6527 - val_accuracy: 0.7857\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5860 - accuracy: 0.8401 - val_loss: 0.6521 - val_accuracy: 0.7857\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5930 - accuracy: 0.8296 - val_loss: 0.6514 - val_accuracy: 0.7857\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6235 - accuracy: 0.7880 - val_loss: 0.6508 - val_accuracy: 0.7857\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6009 - accuracy: 0.7984 - val_loss: 0.6502 - val_accuracy: 0.7857\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5970 - accuracy: 0.8296 - val_loss: 0.6495 - val_accuracy: 0.7857\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5787 - accuracy: 0.8401 - val_loss: 0.6489 - val_accuracy: 0.7857\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5794 - accuracy: 0.8296 - val_loss: 0.6483 - val_accuracy: 0.7857\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6023 - accuracy: 0.8088 - val_loss: 0.6477 - val_accuracy: 0.7857\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5851 - accuracy: 0.8401 - val_loss: 0.6471 - val_accuracy: 0.7857\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5668 - accuracy: 0.8505 - val_loss: 0.6465 - val_accuracy: 0.7857\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5928 - accuracy: 0.8296 - val_loss: 0.6459 - val_accuracy: 0.7857\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5882 - accuracy: 0.8192 - val_loss: 0.6453 - val_accuracy: 0.7857\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5850 - accuracy: 0.8192 - val_loss: 0.6447 - val_accuracy: 0.7857\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5956 - accuracy: 0.8192 - val_loss: 0.6441 - val_accuracy: 0.7857\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5938 - accuracy: 0.8192 - val_loss: 0.6434 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5999 - accuracy: 0.8192 - val_loss: 0.6428 - val_accuracy: 0.7857\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5883 - accuracy: 0.8192 - val_loss: 0.6422 - val_accuracy: 0.7857\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5895 - accuracy: 0.8192 - val_loss: 0.6417 - val_accuracy: 0.7857\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5925 - accuracy: 0.8088 - val_loss: 0.6411 - val_accuracy: 0.8214\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5735 - accuracy: 0.8296 - val_loss: 0.6405 - val_accuracy: 0.8214\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5917 - accuracy: 0.8296 - val_loss: 0.6399 - val_accuracy: 0.8214\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5725 - accuracy: 0.8296 - val_loss: 0.6393 - val_accuracy: 0.8214\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5823 - accuracy: 0.8192 - val_loss: 0.6387 - val_accuracy: 0.8214\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5725 - accuracy: 0.8401 - val_loss: 0.6381 - val_accuracy: 0.8214\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5739 - accuracy: 0.8192 - val_loss: 0.6376 - val_accuracy: 0.8214\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5893 - accuracy: 0.8088 - val_loss: 0.6370 - val_accuracy: 0.8214\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5886 - accuracy: 0.8296 - val_loss: 0.6364 - val_accuracy: 0.8214\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5820 - accuracy: 0.8088 - val_loss: 0.6358 - val_accuracy: 0.8214\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5894 - accuracy: 0.8192 - val_loss: 0.6353 - val_accuracy: 0.8214\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5825 - accuracy: 0.8296 - val_loss: 0.6347 - val_accuracy: 0.8214\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5878 - accuracy: 0.7984 - val_loss: 0.6341 - val_accuracy: 0.8214\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5697 - accuracy: 0.8296 - val_loss: 0.6335 - val_accuracy: 0.8214\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5864 - accuracy: 0.8296 - val_loss: 0.6330 - val_accuracy: 0.8214\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5874 - accuracy: 0.7984 - val_loss: 0.6324 - val_accuracy: 0.8214\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5659 - accuracy: 0.8192 - val_loss: 0.6318 - val_accuracy: 0.8214\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5524 - accuracy: 0.8401 - val_loss: 0.6313 - val_accuracy: 0.8214\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5740 - accuracy: 0.8088 - val_loss: 0.6307 - val_accuracy: 0.8214\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5661 - accuracy: 0.8401 - val_loss: 0.6302 - val_accuracy: 0.8214\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5786 - accuracy: 0.8296 - val_loss: 0.6296 - val_accuracy: 0.8214\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5583 - accuracy: 0.8505 - val_loss: 0.6291 - val_accuracy: 0.8214\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5628 - accuracy: 0.8505 - val_loss: 0.6285 - val_accuracy: 0.8214\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5756 - accuracy: 0.8088 - val_loss: 0.6280 - val_accuracy: 0.8214\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5563 - accuracy: 0.8296 - val_loss: 0.6274 - val_accuracy: 0.8214\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5715 - accuracy: 0.8192 - val_loss: 0.6269 - val_accuracy: 0.8214\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5772 - accuracy: 0.8192 - val_loss: 0.6264 - val_accuracy: 0.8214\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5573 - accuracy: 0.8505 - val_loss: 0.6258 - val_accuracy: 0.8214\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5816 - accuracy: 0.7984 - val_loss: 0.6253 - val_accuracy: 0.8214\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5688 - accuracy: 0.8296 - val_loss: 0.6248 - val_accuracy: 0.8214\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5663 - accuracy: 0.8505 - val_loss: 0.6242 - val_accuracy: 0.8214\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5705 - accuracy: 0.8088 - val_loss: 0.6237 - val_accuracy: 0.8214\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5848 - accuracy: 0.8401 - val_loss: 0.6232 - val_accuracy: 0.8214\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5832 - accuracy: 0.8088 - val_loss: 0.6226 - val_accuracy: 0.8214\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5673 - accuracy: 0.8401 - val_loss: 0.6221 - val_accuracy: 0.8214\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5727 - accuracy: 0.7880 - val_loss: 0.6216 - val_accuracy: 0.8214\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5846 - accuracy: 0.8192 - val_loss: 0.6211 - val_accuracy: 0.8214\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5697 - accuracy: 0.7880 - val_loss: 0.6205 - val_accuracy: 0.8214\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5849 - accuracy: 0.7984 - val_loss: 0.6200 - val_accuracy: 0.8214\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5766 - accuracy: 0.8192 - val_loss: 0.6195 - val_accuracy: 0.8214\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5643 - accuracy: 0.8088 - val_loss: 0.6190 - val_accuracy: 0.8214\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5828 - accuracy: 0.8088 - val_loss: 0.6185 - val_accuracy: 0.8214\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5530 - accuracy: 0.8296 - val_loss: 0.6180 - val_accuracy: 0.8214\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5787 - accuracy: 0.8296 - val_loss: 0.6175 - val_accuracy: 0.8214\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5682 - accuracy: 0.8192 - val_loss: 0.6170 - val_accuracy: 0.8214\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5581 - accuracy: 0.8192 - val_loss: 0.6165 - val_accuracy: 0.8214\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5564 - accuracy: 0.8088 - val_loss: 0.6160 - val_accuracy: 0.8214\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5487 - accuracy: 0.8296 - val_loss: 0.6155 - val_accuracy: 0.8214\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5450 - accuracy: 0.8296 - val_loss: 0.6150 - val_accuracy: 0.8214\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5537 - accuracy: 0.8296 - val_loss: 0.6145 - val_accuracy: 0.8214\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5619 - accuracy: 0.8088 - val_loss: 0.6140 - val_accuracy: 0.8214\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5563 - accuracy: 0.8401 - val_loss: 0.6135 - val_accuracy: 0.8214\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5628 - accuracy: 0.8192 - val_loss: 0.6130 - val_accuracy: 0.8214\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5829 - accuracy: 0.7880 - val_loss: 0.6125 - val_accuracy: 0.8214\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5643 - accuracy: 0.8192 - val_loss: 0.6120 - val_accuracy: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5669 - accuracy: 0.8088 - val_loss: 0.6115 - val_accuracy: 0.8214\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5611 - accuracy: 0.8088 - val_loss: 0.6110 - val_accuracy: 0.8214\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5499 - accuracy: 0.8296 - val_loss: 0.6105 - val_accuracy: 0.8214\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5652 - accuracy: 0.8088 - val_loss: 0.6100 - val_accuracy: 0.8214\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5498 - accuracy: 0.8192 - val_loss: 0.6096 - val_accuracy: 0.8214\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5539 - accuracy: 0.8401 - val_loss: 0.6091 - val_accuracy: 0.8214\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5748 - accuracy: 0.8088 - val_loss: 0.6086 - val_accuracy: 0.8214\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5555 - accuracy: 0.8192 - val_loss: 0.6081 - val_accuracy: 0.8214\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5363 - accuracy: 0.8401 - val_loss: 0.6076 - val_accuracy: 0.8214\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5764 - accuracy: 0.7984 - val_loss: 0.6072 - val_accuracy: 0.8214\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5701 - accuracy: 0.7984 - val_loss: 0.6067 - val_accuracy: 0.8214\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5490 - accuracy: 0.8088 - val_loss: 0.6062 - val_accuracy: 0.8214\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5474 - accuracy: 0.8296 - val_loss: 0.6057 - val_accuracy: 0.8214\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5451 - accuracy: 0.8192 - val_loss: 0.6053 - val_accuracy: 0.8214\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5471 - accuracy: 0.8296 - val_loss: 0.6048 - val_accuracy: 0.8214\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5432 - accuracy: 0.8296 - val_loss: 0.6043 - val_accuracy: 0.8214\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5652 - accuracy: 0.7984 - val_loss: 0.6039 - val_accuracy: 0.8214\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5446 - accuracy: 0.8296 - val_loss: 0.6034 - val_accuracy: 0.8214\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5652 - accuracy: 0.8192 - val_loss: 0.6029 - val_accuracy: 0.8214\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5499 - accuracy: 0.8192 - val_loss: 0.6025 - val_accuracy: 0.8214\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5556 - accuracy: 0.8192 - val_loss: 0.6020 - val_accuracy: 0.8214\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5353 - accuracy: 0.8401 - val_loss: 0.6016 - val_accuracy: 0.8214\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5354 - accuracy: 0.8505 - val_loss: 0.6011 - val_accuracy: 0.8214\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5399 - accuracy: 0.8296 - val_loss: 0.6006 - val_accuracy: 0.8214\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5424 - accuracy: 0.8088 - val_loss: 0.6002 - val_accuracy: 0.8214\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5345 - accuracy: 0.8296 - val_loss: 0.5997 - val_accuracy: 0.8214\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5453 - accuracy: 0.8296 - val_loss: 0.5993 - val_accuracy: 0.8214\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5288 - accuracy: 0.8401 - val_loss: 0.5989 - val_accuracy: 0.8214\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5556 - accuracy: 0.8296 - val_loss: 0.5984 - val_accuracy: 0.8214\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5315 - accuracy: 0.8296 - val_loss: 0.5980 - val_accuracy: 0.8214\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5568 - accuracy: 0.7984 - val_loss: 0.5975 - val_accuracy: 0.8214\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5629 - accuracy: 0.7880 - val_loss: 0.5971 - val_accuracy: 0.8214\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5194 - accuracy: 0.8505 - val_loss: 0.5966 - val_accuracy: 0.8214\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5451 - accuracy: 0.8192 - val_loss: 0.5962 - val_accuracy: 0.8214\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5494 - accuracy: 0.8192 - val_loss: 0.5957 - val_accuracy: 0.8214\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5385 - accuracy: 0.8192 - val_loss: 0.5953 - val_accuracy: 0.8214\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5181 - accuracy: 0.8401 - val_loss: 0.5949 - val_accuracy: 0.8214\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5275 - accuracy: 0.8296 - val_loss: 0.5944 - val_accuracy: 0.8214\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5446 - accuracy: 0.8296 - val_loss: 0.5940 - val_accuracy: 0.8214\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5443 - accuracy: 0.8192 - val_loss: 0.5936 - val_accuracy: 0.8214\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5397 - accuracy: 0.8296 - val_loss: 0.5931 - val_accuracy: 0.8214\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5378 - accuracy: 0.8088 - val_loss: 0.5927 - val_accuracy: 0.8214\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5307 - accuracy: 0.8192 - val_loss: 0.5923 - val_accuracy: 0.8214\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5304 - accuracy: 0.8505 - val_loss: 0.5918 - val_accuracy: 0.8214\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5335 - accuracy: 0.8296 - val_loss: 0.5914 - val_accuracy: 0.8214\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5444 - accuracy: 0.8088 - val_loss: 0.5910 - val_accuracy: 0.8214\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5372 - accuracy: 0.8192 - val_loss: 0.5906 - val_accuracy: 0.8214\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5309 - accuracy: 0.8401 - val_loss: 0.5901 - val_accuracy: 0.8214\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5422 - accuracy: 0.8296 - val_loss: 0.5897 - val_accuracy: 0.8214\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5387 - accuracy: 0.8192 - val_loss: 0.5893 - val_accuracy: 0.8214\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5457 - accuracy: 0.8088 - val_loss: 0.5889 - val_accuracy: 0.8214\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5083 - accuracy: 0.8505 - val_loss: 0.5885 - val_accuracy: 0.8214\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5409 - accuracy: 0.8088 - val_loss: 0.5880 - val_accuracy: 0.8214\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5343 - accuracy: 0.8296 - val_loss: 0.5876 - val_accuracy: 0.8214\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5448 - accuracy: 0.8296 - val_loss: 0.5872 - val_accuracy: 0.8214\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5429 - accuracy: 0.8088 - val_loss: 0.5868 - val_accuracy: 0.8214\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5346 - accuracy: 0.8296 - val_loss: 0.5864 - val_accuracy: 0.8214\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5112 - accuracy: 0.8401 - val_loss: 0.5860 - val_accuracy: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5349 - accuracy: 0.8296 - val_loss: 0.5856 - val_accuracy: 0.8214\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5366 - accuracy: 0.7984 - val_loss: 0.5852 - val_accuracy: 0.8214\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5271 - accuracy: 0.8401 - val_loss: 0.5848 - val_accuracy: 0.8214\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5447 - accuracy: 0.8088 - val_loss: 0.5844 - val_accuracy: 0.8214\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5124 - accuracy: 0.8296 - val_loss: 0.5839 - val_accuracy: 0.8214\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5276 - accuracy: 0.8192 - val_loss: 0.5835 - val_accuracy: 0.8214\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5394 - accuracy: 0.8192 - val_loss: 0.5831 - val_accuracy: 0.8214\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5083 - accuracy: 0.8401 - val_loss: 0.5827 - val_accuracy: 0.8214\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5304 - accuracy: 0.8088 - val_loss: 0.5823 - val_accuracy: 0.8214\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5406 - accuracy: 0.7984 - val_loss: 0.5819 - val_accuracy: 0.8214\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5285 - accuracy: 0.8192 - val_loss: 0.5815 - val_accuracy: 0.8214\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5273 - accuracy: 0.8192 - val_loss: 0.5811 - val_accuracy: 0.8214\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5218 - accuracy: 0.8505 - val_loss: 0.5807 - val_accuracy: 0.8214\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5211 - accuracy: 0.8296 - val_loss: 0.5803 - val_accuracy: 0.8214\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5276 - accuracy: 0.8296 - val_loss: 0.5799 - val_accuracy: 0.8214\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5418 - accuracy: 0.8088 - val_loss: 0.5795 - val_accuracy: 0.8214\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5249 - accuracy: 0.8192 - val_loss: 0.5791 - val_accuracy: 0.8214\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5134 - accuracy: 0.8296 - val_loss: 0.5787 - val_accuracy: 0.8214\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5209 - accuracy: 0.8088 - val_loss: 0.5783 - val_accuracy: 0.8214\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5365 - accuracy: 0.7984 - val_loss: 0.5779 - val_accuracy: 0.8214\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5129 - accuracy: 0.8296 - val_loss: 0.5775 - val_accuracy: 0.8214\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5295 - accuracy: 0.8088 - val_loss: 0.5771 - val_accuracy: 0.8214\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5164 - accuracy: 0.8401 - val_loss: 0.5767 - val_accuracy: 0.8214\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5308 - accuracy: 0.8192 - val_loss: 0.5764 - val_accuracy: 0.8214\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5290 - accuracy: 0.8296 - val_loss: 0.5760 - val_accuracy: 0.8214\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5219 - accuracy: 0.8296 - val_loss: 0.5756 - val_accuracy: 0.8214\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5103 - accuracy: 0.8296 - val_loss: 0.5752 - val_accuracy: 0.8214\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5183 - accuracy: 0.8296 - val_loss: 0.5748 - val_accuracy: 0.8214\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5262 - accuracy: 0.8088 - val_loss: 0.5744 - val_accuracy: 0.8214\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5187 - accuracy: 0.8088 - val_loss: 0.5741 - val_accuracy: 0.8214\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5083 - accuracy: 0.8296 - val_loss: 0.5737 - val_accuracy: 0.8214\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5339 - accuracy: 0.8088 - val_loss: 0.5733 - val_accuracy: 0.8214\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5205 - accuracy: 0.8192 - val_loss: 0.5729 - val_accuracy: 0.8214\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5342 - accuracy: 0.7984 - val_loss: 0.5725 - val_accuracy: 0.8214\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5450 - accuracy: 0.7776 - val_loss: 0.5722 - val_accuracy: 0.8214\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5206 - accuracy: 0.7984 - val_loss: 0.5718 - val_accuracy: 0.8214\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5059 - accuracy: 0.8401 - val_loss: 0.5714 - val_accuracy: 0.8214\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5227 - accuracy: 0.7984 - val_loss: 0.5710 - val_accuracy: 0.8214\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5054 - accuracy: 0.8296 - val_loss: 0.5707 - val_accuracy: 0.8214\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5244 - accuracy: 0.8088 - val_loss: 0.5703 - val_accuracy: 0.8214\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5058 - accuracy: 0.8505 - val_loss: 0.5699 - val_accuracy: 0.8214\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5312 - accuracy: 0.7984 - val_loss: 0.5695 - val_accuracy: 0.8214\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5089 - accuracy: 0.8192 - val_loss: 0.5692 - val_accuracy: 0.8214\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5139 - accuracy: 0.8088 - val_loss: 0.5688 - val_accuracy: 0.8214\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5349 - accuracy: 0.8088 - val_loss: 0.5684 - val_accuracy: 0.8214\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5014 - accuracy: 0.8296 - val_loss: 0.5681 - val_accuracy: 0.8214\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5085 - accuracy: 0.8296 - val_loss: 0.5677 - val_accuracy: 0.8214\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5086 - accuracy: 0.8192 - val_loss: 0.5673 - val_accuracy: 0.8214\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5172 - accuracy: 0.8088 - val_loss: 0.5670 - val_accuracy: 0.8214\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4873 - accuracy: 0.8505 - val_loss: 0.5666 - val_accuracy: 0.8214\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5008 - accuracy: 0.8505 - val_loss: 0.5663 - val_accuracy: 0.8214\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4985 - accuracy: 0.8505 - val_loss: 0.5659 - val_accuracy: 0.8214\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4963 - accuracy: 0.8296 - val_loss: 0.5656 - val_accuracy: 0.8214\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4978 - accuracy: 0.8296 - val_loss: 0.5652 - val_accuracy: 0.8214\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5213 - accuracy: 0.8192 - val_loss: 0.5648 - val_accuracy: 0.8214\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5166 - accuracy: 0.8088 - val_loss: 0.5645 - val_accuracy: 0.8571\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.8401 - val_loss: 0.5641 - val_accuracy: 0.8571\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5105 - accuracy: 0.8296 - val_loss: 0.5638 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5156 - accuracy: 0.7984 - val_loss: 0.5634 - val_accuracy: 0.8571\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4990 - accuracy: 0.8192 - val_loss: 0.5631 - val_accuracy: 0.8571\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5021 - accuracy: 0.8296 - val_loss: 0.5627 - val_accuracy: 0.8571\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5082 - accuracy: 0.8192 - val_loss: 0.5624 - val_accuracy: 0.8571\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5248 - accuracy: 0.8088 - val_loss: 0.5620 - val_accuracy: 0.8571\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5212 - accuracy: 0.8192 - val_loss: 0.5617 - val_accuracy: 0.8571\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4931 - accuracy: 0.8192 - val_loss: 0.5613 - val_accuracy: 0.8571\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5380 - accuracy: 0.7880 - val_loss: 0.5610 - val_accuracy: 0.8571\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5124 - accuracy: 0.7984 - val_loss: 0.5606 - val_accuracy: 0.8571\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5114 - accuracy: 0.8088 - val_loss: 0.5603 - val_accuracy: 0.8571\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5056 - accuracy: 0.8192 - val_loss: 0.5599 - val_accuracy: 0.8571\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5150 - accuracy: 0.8401 - val_loss: 0.5596 - val_accuracy: 0.8571\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5055 - accuracy: 0.8192 - val_loss: 0.5593 - val_accuracy: 0.8571\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5099 - accuracy: 0.8192 - val_loss: 0.5589 - val_accuracy: 0.8571\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4975 - accuracy: 0.8296 - val_loss: 0.5586 - val_accuracy: 0.8571\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5227 - accuracy: 0.8296 - val_loss: 0.5582 - val_accuracy: 0.8571\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5006 - accuracy: 0.8192 - val_loss: 0.5579 - val_accuracy: 0.8571\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4785 - accuracy: 0.8505 - val_loss: 0.5576 - val_accuracy: 0.8571\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5006 - accuracy: 0.8401 - val_loss: 0.5572 - val_accuracy: 0.8571\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5308 - accuracy: 0.7984 - val_loss: 0.5569 - val_accuracy: 0.8571\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5069 - accuracy: 0.8192 - val_loss: 0.5565 - val_accuracy: 0.8571\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5034 - accuracy: 0.8401 - val_loss: 0.5562 - val_accuracy: 0.8571\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5150 - accuracy: 0.8192 - val_loss: 0.5559 - val_accuracy: 0.8571\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4968 - accuracy: 0.8088 - val_loss: 0.5555 - val_accuracy: 0.8571\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4942 - accuracy: 0.8296 - val_loss: 0.5552 - val_accuracy: 0.8571\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5010 - accuracy: 0.8296 - val_loss: 0.5549 - val_accuracy: 0.8571\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4995 - accuracy: 0.8088 - val_loss: 0.5545 - val_accuracy: 0.8571\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5118 - accuracy: 0.7984 - val_loss: 0.5542 - val_accuracy: 0.8571\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4943 - accuracy: 0.8401 - val_loss: 0.5539 - val_accuracy: 0.8571\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4827 - accuracy: 0.8401 - val_loss: 0.5535 - val_accuracy: 0.8571\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4987 - accuracy: 0.8296 - val_loss: 0.5532 - val_accuracy: 0.8571\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4858 - accuracy: 0.8296 - val_loss: 0.5529 - val_accuracy: 0.8571\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4888 - accuracy: 0.8192 - val_loss: 0.5526 - val_accuracy: 0.8571\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5092 - accuracy: 0.8192 - val_loss: 0.5522 - val_accuracy: 0.8571\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4978 - accuracy: 0.8192 - val_loss: 0.5519 - val_accuracy: 0.8571\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4940 - accuracy: 0.8401 - val_loss: 0.5516 - val_accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs_num, validation_split=0.3, callbacks=[extractor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "distinct-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_output = extractor.get_testing_results()\n",
    "\n",
    "all_predictions = []\n",
    "for epoch in extractor.get_stored_predictions():\n",
    "    epoch_predictions = []\n",
    "    for dp in epoch:\n",
    "        epoch_predictions.append(int(dp.argmax()))                       \n",
    "    all_predictions.append(epoch_predictions)\n",
    "\n",
    "extractor.set_stored_predictions(all_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exotic-rebate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1], [2, 2, 1], [2, 2, 1], [2, 2, 1], [2, 2, 1], [2, 2, 1], [2, 2, 1], [2, 2, 1], [2, 2, 1], [0, 2, 1], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(extractor.get_stored_predictions())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-constitutional",
   "metadata": {},
   "source": [
    "Let's make a plot of the accuracy and loss per epoch from the model training. What trends do you see here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continental-anchor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-feature",
   "metadata": {
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Let's see how the model performs on brand new, unseen before data. Two values will be returned: loss (a number which represents our error, lower values are better), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incredible-maine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7555258  0.37211293 0.1854664 ]\n",
      " [0.13026562 0.52186555 0.70985407]\n",
      " [0.7590202  0.40183365 0.17739275]\n",
      " [0.19557773 0.54194653 0.6100821 ]\n",
      " [0.7459127  0.43727344 0.19650015]\n",
      " [0.78505176 0.44534484 0.16622378]\n",
      " [0.7705698  0.293907   0.17891838]\n",
      " [0.76150954 0.26780194 0.17345591]\n",
      " [0.1174363  0.5271054  0.725692  ]\n",
      " [0.16238192 0.59500486 0.65082055]\n",
      " [0.09865963 0.5367219  0.7426784 ]\n",
      " [0.09836984 0.529815   0.74047595]\n",
      " [0.1152427  0.5479149  0.7263268 ]\n",
      " [0.73923284 0.3579337  0.19082882]\n",
      " [0.80483687 0.3659477  0.14863753]\n",
      " [0.14249977 0.54330987 0.683565  ]\n",
      " [0.18446723 0.55205166 0.6172145 ]\n",
      " [0.7107149  0.43945798 0.22070554]\n",
      " [0.7449283  0.3714721  0.1929436 ]\n",
      " [0.7016601  0.38414615 0.22568569]\n",
      " [0.79641145 0.3018505  0.1506357 ]\n",
      " [0.7508959  0.4059311  0.19411147]\n",
      " [0.7432665  0.35854483 0.20048025]\n",
      " [0.75798243 0.45056915 0.18318523]\n",
      " [0.74235153 0.38604972 0.19490105]\n",
      " [0.7539728  0.37611786 0.1855442 ]\n",
      " [0.6872131  0.53784645 0.244958  ]\n",
      " [0.6960352  0.39306456 0.21886046]\n",
      " [0.75457203 0.34579575 0.18466145]\n",
      " [0.745907   0.39855292 0.19377604]\n",
      " [0.26982647 0.5508292  0.53450334]\n",
      " [0.22943172 0.48602214 0.57245123]\n",
      " [0.40831223 0.5850825  0.42260015]\n",
      " [0.22985412 0.51338327 0.59332484]\n",
      " [0.35177517 0.63396436 0.4806572 ]\n",
      " [0.23897631 0.4843108  0.5826082 ]\n",
      " [0.26400372 0.5363319  0.5311086 ]\n",
      " [0.21181434 0.5202448  0.58309615]\n",
      " [0.25657958 0.5123784  0.5647658 ]\n",
      " [0.23855329 0.53650415 0.57011265]\n",
      " [0.3648179  0.54122    0.4691626 ]\n",
      " [0.3223329  0.5822611  0.5024808 ]\n",
      " [0.31009772 0.5424117  0.51032984]\n",
      " [0.18324757 0.57861894 0.6301688 ]\n",
      " [0.26189455 0.47804132 0.53090227]\n",
      " [0.21084754 0.49502814 0.6087056 ]\n",
      " [0.28385988 0.57543695 0.5235598 ]\n",
      " [0.2470607  0.51985633 0.5597715 ]\n",
      " [0.2864994  0.5590855  0.52289206]\n",
      " [0.29712147 0.5314053  0.5093861 ]\n",
      " [0.41333944 0.56347877 0.42422473]\n",
      " [0.14397119 0.563949   0.6756816 ]\n",
      " [0.09520072 0.55014074 0.7617571 ]\n",
      " [0.1094766  0.60492617 0.7418891 ]\n",
      " [0.08687337 0.48676735 0.7591061 ]\n",
      " [0.14662102 0.54326224 0.6749818 ]\n",
      " [0.04830244 0.60592234 0.85417485]\n",
      " [0.16983604 0.6322229  0.66190106]\n",
      " [0.16340244 0.57200795 0.6635521 ]\n",
      " [0.12393679 0.515485   0.7008603 ]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   Iris-setosa       1.00      1.00      1.00        21\n",
      "Iris-versicolo       1.00      0.52      0.69        21\n",
      "Iris-virginica       0.64      1.00      0.78        18\n",
      "\n",
      "      accuracy                           0.83        60\n",
      "     macro avg       0.88      0.84      0.82        60\n",
      "  weighted avg       0.89      0.83      0.83        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# make a prediction\n",
    "testingPredictions = model.predict(x_test)\n",
    "testingPredictions = list(testingPredictions.argmax(axis=-1))\n",
    "\n",
    "confidence_scores = model.predict(x_test, batch_size=32)\n",
    "print(confidence_scores)\n",
    "\n",
    "target_names = ['Iris-setosa', 'Iris-versicolo', 'Iris-virginica']\n",
    "print(classification_report(y_test.argmax(axis=-1), testingPredictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "civilian-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.8333\n",
      "loss: 0.531\n",
      "accuracy: 0.833\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-macro",
   "metadata": {},
   "source": [
    "Now, we need to export the data in order to support some interactive visualizations that we've created. Feel free to skip over this code block and move to the interactive visualizations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "homeless-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# output_directory = \"libraries/\"\n",
    "# output_filename = \"predict_LR.json\"\n",
    "# full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "# true_label = []\n",
    "# for i in range(len(y_test)):\n",
    "#     for j in range(len(y_test[i])):\n",
    "#         if y_test[i][j] == 1:\n",
    "#             if j == 0:\n",
    "#                 true_label.append(target_names[0])\n",
    "#             if j == 1:\n",
    "#                 true_label.append(target_names[1])\n",
    "#             if j == 2:\n",
    "#                 true_label.append(target_names[2])\n",
    "\n",
    "\n",
    "# for i in range(len(testingPredictions)):\n",
    "#     if testingPredictions[i] == 0:\n",
    "#         testingPredictions[i] = target_names[0]\n",
    "#     if testingPredictions[i] == 1:\n",
    "#         testingPredictions[i] = target_names[1]\n",
    "#     if testingPredictions[i] == 2:\n",
    "#         testingPredictions[i] = target_names[2]\n",
    "\n",
    "# data = []\n",
    "# data.extend([{\n",
    "#       'index': i,\n",
    "#       'true_label': true_label[i],\n",
    "#       'predicted_label': testingPredictions[i],\n",
    "#       'confidence_score': confidence_scores.tolist()[i],\n",
    "#       'features': x_test.tolist()[i]\n",
    "#   } for i in range(len(testingPredictions))])\n",
    "\n",
    "\n",
    "\n",
    "# with open(full_path, 'w') as outfile:\n",
    "#     json.dump(data, outfile, indent=4, sort_keys=False)\n",
    "    \n",
    "# collected_epoch_filename = 'predict_LR_extended.json'\n",
    "# full_path_extended = os.path.join(output_directory, collected_epoch_filename)\n",
    "\n",
    "# extended_data = {}\n",
    "# for i, table in enumerate(epoch_history_extracted_data):\n",
    "#     jsonified = table.to_json(orient='index')\n",
    "#     parsed = json.loads(jsonified)\n",
    "# #     extended_data.append(parsed)\n",
    "#     extended_data[f'{i}'] = parsed\n",
    "    \n",
    "# # print(extended_data)\n",
    "    \n",
    "# with open(full_path_extended, 'w') as outfile:\n",
    "#     json.dump(extended_data, outfile, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "recreational-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_directory = \"libraries/\"\n",
    "output_filename = \"predict_LR_extended.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "data = {}\n",
    "for i in range(len(epoch_output[0])):\n",
    "    data[i] = {}\n",
    "    data[i]['Num Epochs'] = len(epoch_output)\n",
    "    data[i]['Index'] = i\n",
    "    data[i]['Test Label'] = int(epoch_output[0]['actual'][i].argmax())\n",
    "    data[i]['Test Prediction'] = {}\n",
    "    data[i]['Test Confidence Score'] = {}\n",
    "    data[i]['Intermediate Values'] = {}\n",
    "    for j in range(len(epoch_output)):\n",
    "        data[i]['Test Prediction'][j] = int(epoch_output[j]['prediction'][i])\n",
    "        data[i]['Test Confidence Score'][j] = epoch_output[j]['confidence_score'][i].tolist()\n",
    "        data[i]['Intermediate Values'][j] = epoch_output[j]['intermediate_values'][i]\n",
    "    data[i]['Test Sentence'] = epoch_output[0]['input'][i].tolist()\n",
    "    \n",
    "with open(full_path, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "quarterly-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "output_directory = \"libraries/\"\n",
    "collected_epoch_filename = 'predict_LR_extended.json'\n",
    "full_path_extended = os.path.join(output_directory, collected_epoch_filename)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import libraries.mlvislib as mlvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "enclosed-publicity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t<style> \n",
       "\t\tbody {\n",
       "\t\t\tfont-family: Arial, sans-serif;\n",
       "\t\t\tfont-size: larger;\n",
       "\t\t}\n",
       "\t\t.box_highlighted { \n",
       "\t\t\tbackground-color: #ffb; \n",
       "\t\t\tborder: 1px solid #b53;\n",
       "\t\t}\n",
       "\t\t.highlight{\n",
       "\t\t\tbackground-color: yellow;\n",
       "\t\t}\n",
       "\t\t.lighthigh{\n",
       "\t\t\tbackground-color: green;\n",
       "\t\t}\n",
       "\t\tli{\n",
       "\t\t\tfont-size: smaller;\n",
       "\t\t}\n",
       "\t\ttd{\n",
       "\t\t\tmin-width: 100px;\n",
       "\t\t}\n",
       "\t\t#review{\n",
       "\t\t\tborder:1px solid pink; \n",
       "\t\t\tpadding: 5px; \n",
       "\t\t\tfloat: left; \n",
       "\t\t\twidth: 750px; \n",
       "\t\t\theight: 500px; \n",
       "\t\t\tbackground-color: white;\n",
       "\t\t\tmargin: 20px;\n",
       "\t\t\toverflow: scroll;\n",
       "\t\t\t}\n",
       "\t\t#matrix{\n",
       "\t\t\tborder:1px solid pink; \n",
       "\t\t\tpadding: 5px; \n",
       "\t\t\tfloat: left;\n",
       "\t\t\tmargin: 20px;\n",
       "\t\t}\n",
       "\t\t#slider {\n",
       "\t\t  -webkit-appearance: none;\n",
       "\t\t  width: 100%;\n",
       "\t\t  height: 15px;\n",
       "\t\t  border-radius: 5px;  \n",
       "\t\t  background: #d3d3d3;\n",
       "\t\t  outline: none;\n",
       "\t\t  opacity: 0.7;\n",
       "\t\t  -webkit-transition: .2s;\n",
       "\t\t  transition: opacity .2s;\n",
       "\t\t}\n",
       "\t\t#slider::-webkit-slider-thumb {\n",
       "\t\t  -webkit-appearance: none;\n",
       "\t\t  appearance: none;\n",
       "\t\t  width: 25px;\n",
       "\t\t  height: 25px;\n",
       "\t\t  border-radius: 50%; \n",
       "\t\t  background: #4ca2af;\n",
       "\t\t  cursor: pointer;\n",
       "\t\t}\n",
       "\t\t#slider::-moz-range-thumb {\n",
       "\t\t  width: 25px;\n",
       "\t\t  height: 25px;\n",
       "\t\t  border-radius: 50%;\n",
       "\t\t  background: #4ca2af;\n",
       "\t\t  cursor: pointer;\n",
       "\t\t}\n",
       "\t\t </style>\n",
       "\t\t<h1> Interactive Confusion Matrix </h1>\n",
       "\t\t<h3 id=\"confidence_setting\"> Confidence: 0.5 </h3>\n",
       "\t\t<input class=\"slider\" id=\"confidence_slider\" type=\"range\" min=\"0\" max=\"1\" step=\".1\" value=\".5\"/>\n",
       "\t\t<h3 id=\"epoch_setting\"> Epoch: 1 </h3>\n",
       "\t\t<input class=\"slider\" id=\"epoch_slider\" type=\"range\" min=\"1\" max=\"20\" step=\"1\" value=\"1\"/>\n",
       "\t\t<div>\n",
       "\t\t\t<div>\n",
       "\t\t\t\t<div id=\"matrix\"></div>\n",
       "\t\t\t\t<div id=\"review\">\n",
       "\t\t\t\t\tData \n",
       "\t\t\t\t\t<ul id = \"testList\"></ul>\n",
       "\t\t\t\t</div>\n",
       "\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t<script> \n",
       "\t\tconsole.log(\"Visualization: Running JavaScript...\");\n",
       "\t\tvar dname = \"libraries/predict_LR_extended.json\";\n",
       "\t\tvar currentConfSetting = .5;\n",
       "\t\tvar currentEpochSetting = 1;\n",
       "\t\tvar lastEpochIndex = 0;\n",
       "\t\tconsole.log(\"Visualization: Reading JSON file(\", dname, \")...\");\n",
       "\n",
       "\t\td3.json( \"libraries/predict_LR_extended.json\", function(d) {\n",
       "\t\t\tconsole.log(\"Visualization: Logging complete JSON...\");\n",
       "\t\t\tconsole.log(d);\n",
       "\t\t\tlastEpochIndex = d[0]['Num Epochs']\n",
       "\t\t\td3.select(\"#epoch_slider\").attr(\"max\", lastEpochIndex);\n",
       "\t\t});\n",
       "\n",
       "\n",
       "\t\t/*--------------------------------------------------------------------------------\n",
       "\t\tI've temporarily left out the 'getType' function, since the names of these\n",
       "\t\ttypes are not included in the JSON file that is given to the JavaScript. More\n",
       "\t\tfunctionality can be incldued later to bring the names in as well as the raw data.\n",
       "\t\tType will be represented by the given numeric identifier for now.\n",
       "\t\t--------------------------------------------------------------------------------*/\n",
       "\n",
       "\t\t/*--------------------------------------------------------------------------------\n",
       "\t\tFunction: extractTypes\n",
       "\t\tBehavior: Identifies different types each data point can be identified as, based \n",
       "\t\t\t\t  off of the 'true_label' attribute in JSON file.\n",
       "\t\tInput: JSON file\n",
       "\t\tOutput: Returns array of possible values for 'Test Label'.\n",
       "\t\t--------------------------------------------------------------------------------*/\n",
       "\n",
       "\t\tfunction extractTypes(data){\n",
       "\t\t\tvar lookup = {};\n",
       "\t\t\tvar items = data;\n",
       "\t\t\tvar result = [];\n",
       "\n",
       "\t\t\tfor (var item, i=0; item = items[i++];){\n",
       "\t\t\t\tvar name = item['Test Label'];\n",
       "\t\t\t\tif(!(name in lookup)){\n",
       "\t\t\t\t\tlookup[name] = 1;\n",
       "\t\t\t\t\tresult.push(name);\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\n",
       "\t\t\treturn result;\n",
       "\t\t}\n",
       "\n",
       "\t\t/*--------------------------------------------------------------------------------\n",
       "\t\tFunction: Slider Re-Draw\n",
       "\t\tBehavior: This d3 code will redraw each time there is a change in the slider.\n",
       "\t\tInput: None\n",
       "\t\tOutput: Visualization should be redrawn\n",
       "\t\t--------------------------------------------------------------------------------*/\n",
       "\t\t/*--------------------------------------------------------------------------------\n",
       "\t\tBUG: This should be adjusted to be called both on load and on change. \n",
       "\t\t--------------------------------------------------------------------------------*/\n",
       "\n",
       "\t\td3.selectAll(\".slider\").on(\"change\", function() {\n",
       "\t\t\td3.select(\"svg\").remove();\n",
       "\n",
       "\t\t\tif(this.id == \"confidence_slider\"){\n",
       "\t\t\t\tcurrentConfSetting = this.value;\n",
       "\t\t\t}\n",
       "\t\t\tif(this.id == \"epoch_slider\"){\n",
       "\t\t\t\tcurrentEpochSetting = this.value;\n",
       "\t\t\t}\n",
       "\n",
       "\t\t\td3.select(\"#confidence_setting\").text(\"Confidence: \" + currentConfSetting);\n",
       "\t\t\td3.select(\"#epoch_setting\").text(\"Epoch: \" + currentEpochSetting);\n",
       "\t\t\tconsole.log(\"Visualization: Confidence set to (\", currentConfSetting,\n",
       "\t\t\t\t\t\t\") Epoch set to (\", currentEpochSetting, \")\");\n",
       "\n",
       "\t\t\t/*--------------------------------------------------------------------------------\n",
       "\t\t\tFunction: Re-Draw\n",
       "\t\t\tBehavior: Adjusting the slider will call this function to redraw the\n",
       "\t\t\t\t\t  visualization. First a table is build keep track of the number of\n",
       "\t\t\t\t\t  elements to be in each cell. Next, data is read into an array based on\n",
       "\t\t\t\t\t  the parameters set by the sliders.\n",
       "\t\t\tInput: filepath to JSON\n",
       "\t\t\tOutput: visualization should be redrawn\n",
       "\t\t\t--------------------------------------------------------------------------------*/\n",
       "\n",
       "\t\t\td3.json(\"libraries/predict_LR_extended.json\", function(d) {\n",
       "\n",
       "\t\t\t\tvar totalItems = Object.keys(d).length\n",
       "\t\t\t\tconsole.log(\"Visualization: \", totalItems, \"pieces of test data included\")\n",
       "\n",
       "\t\t\t\tvar possibleOutputValues = extractTypes(d);\n",
       "\t\t\t\tconsole.log(\"Visualization: Possible outcomes inlcudes; \", possibleOutputValues)\n",
       "\n",
       "\t\t\t\tvar tableDimension = extractTypes(d).length;\n",
       "\t\t\t\tconsole.log(\"Visualization: Constructing\", tableDimension, \"x\",\n",
       "\t\t\t\t\t\t\ttableDimension, \"chart...\");\n",
       "\t\t\t\tvar dataset = [];\n",
       "\n",
       "\t\t\t\tvar table = new Array(tableDimension);\n",
       "\t\t\t\tfor(var i=0; i<tableDimension; i++){\n",
       "\t\t\t\t\ttable[i] = new Array(tableDimension);\n",
       "\t\t\t\t\tfor(var j=0; j<tableDimension; j++){\n",
       "\t\t\t\t\t\ttable[i][j] = 0;\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t}\n",
       "\t\t\t\tconsole.log(\"Visualization: Table initialized as: \", table)\n",
       "\n",
       "\n",
       "\t\t\t\t/*\n",
       "\t\t\t\t# NOTE: To be removed, we only need to know the integer representation \n",
       "\t\t\t\t#\t\tof which epoch we are using.\n",
       "\t\t\t\tvar selectedEpoch = {};\n",
       "\n",
       "\t\t\t\tfor(var singleEpoch, i=0; singleEpoch = d[i++];){\n",
       "\t\t\t\t\tif((singleEpoch[0][\"Epoch\"] + 1) == parseInt(currentEpochSetting)){\n",
       "\t\t\t\t\t\tselectedEpoch = singleEpoch;\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t}\n",
       "\t\t\t\t*/\n",
       "\n",
       "\t\t\t\tconsole.log(\"Visualization: Preparing to display epoch (\", currentEpochSetting, \")...\");\n",
       "\n",
       "\t\t\t\t/*--------------------------------------------------------------------------------\n",
       "\t\t\t\tNOTE: Will we need to display just integer representations of classifications,\n",
       "\t\t\t\t\t  or will we need to display titles of classicications along the axis\n",
       "\t\t\t\t--------------------------------------------------------------------------------*/\n",
       "\n",
       "\t\t\t\t// NOTE EDITING HERE\n",
       "\n",
       "\t\t\t\tfor(var jsonEntry, i=0; jsonEntry = d[i++];){\n",
       "                    // console.log(\"Debugging: jsonEntry \", jsonEntry);\n",
       "\t\t\t\t\tvar index = i;\n",
       "\t\t\t\t\t// var epoch = jsonEntry[\"Epoch\"];\n",
       "\t\t\t\t\tvar entryText = jsonEntry[\"Test Sentence\"];\n",
       "\t\t\t\t\tvar confidenceScore = jsonEntry[\"Test Confidence Score\"][currentEpochSetting-1];\n",
       "\t\t\t\t\tvar trueLabel = jsonEntry[\"Test Label\"];\n",
       "                    // console.log(\"Debugging: trueLabel \", trueLabel);\n",
       "                    // console.log(typeof trueLabel);\n",
       "\t\t\t\t\tvar predictedLabel = jsonEntry[\"Test Prediction\"][currentEpochSetting-1];\n",
       "                    // console.log(\"Debugging: predictedLabel \", predictedLabel);\n",
       "                    // console.log(typeof predictedLabel);\n",
       "\t\t\t\t\tvar tableXCoordinate = possibleOutputValues.indexOf(predictedLabel); //Predicted\n",
       "                    // console.log(\"Debugging: tableXCoordinate \", tableXCoordinate);\n",
       "                    // console.log(typeof tableXCoordinate);\n",
       "\t\t\t\t\tvar tableYCoordinate = possibleOutputValues.indexOf(trueLabel); // Actual\n",
       "                    // console.log(\"Debugging: tableYCoordinate \", tableYCoordinate);\n",
       "                    // console.log(typeof tableYCoordinate);\n",
       "\n",
       "\t\t\t\t\tif(confidenceScore < currentConfSetting){\n",
       "\t\t\t\t\t\ttable[tableXCoordinate][tableYCoordinate]+=1;\n",
       "\t\t\t\t\t\tdataset.push([trueLabel, predictedLabel, entryText, index]);\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t}\n",
       "\n",
       "\t\t\t\tconsole.log(\"Visualization: Table for confidence \", currentConfSetting, \" at epoch \", currentEpochSetting, table);\n",
       "\t\t\t\tconsole.log(\"Visualization: Creating SVG...\");\n",
       "\n",
       "\t\t\t\t/*--------------------------------------------------------------------------------\n",
       "\t\t\t\tNOTE: Will leave this as the default viz size for now\n",
       "\t\t\t\t--------------------------------------------------------------------------------*/\n",
       "\n",
       "\t\t\t\tvar w = 750;\n",
       "\t\t\t\tvar h = 750;\n",
       "\n",
       "\t\t\t\tvar svg = d3.select(\"body\")\n",
       "\t\t\t\t\t\t\t.select(\"#matrix\")\n",
       "\t\t\t\t\t\t\t.append(\"svg\")\n",
       "\t\t\t\t\t\t\t.attr(\"width\", w)\n",
       "\t\t\t\t\t\t\t.attr(\"height\", h);\n",
       "\n",
       "\t\t\t\tvar rect = svg.selectAll(\"rect\")\n",
       "\t\t\t\t\t\t\t  .data(dataset)\n",
       "\t\t\t\t\t\t\t  .enter()\n",
       "\t\t\t\t\t\t\t  .append(\"rect\");\n",
       "\n",
       "\t\t\t\tvar counters = new Array(tableDimension * tableDimension).fill(0);\n",
       "\t\t\t\tvar ycounters = new Array(tableDimension * tableDimension).fill(0);\n",
       "\t\t\t\tvar cellDimension = h / tableDimension;\n",
       "\t\t\t\tvar blockStackDimension = Math.round(Math.sqrt(totalItems)) + 1;\n",
       "\t\t\t\tvar marginBuffer = 5;\n",
       "\t\t\t\tvar cubeDimension = ((cellDimension - marginBuffer) / blockStackDimension);\n",
       "\n",
       "\t\t\t\t/*--------------------------------------------------------------------------------\n",
       "\t\t\t\tFormat: d[trueLabel, predictedLabel, entryText, index, epoch]\n",
       "\t\t\t\t--------------------------------------------------------------------------------*/\n",
       "\n",
       "\t\t\t\trect.attr(\"x\", function (d, i){\n",
       "\t\t\t\t\tvar matrixnum = (parseInt(d[1]) * tableDimension) + parseInt(d[0]);\n",
       "\t\t\t\t\tvar inmatrixcol = counters[matrixnum] % blockStackDimension;\n",
       "\t\t\t\t\tcounters[matrixnum]++;\n",
       "\t\t\t\t\treturn (d[1] * (cellDimension + marginBuffer)) + (inmatrixcol * (cubeDimension));\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.attr(\"y\", function(d, i){\n",
       "\t\t\t\t\t\tvar matrixnum = (parseInt(d[1] * tableDimension) + parseInt(d[0]));\n",
       "\t\t\t\t\t\tvar hm = Math.floor(ycounters[matrixnum]/blockStackDimension);\n",
       "\t\t\t\t\t\tycounters[matrixnum]++;\n",
       "\t\t\t\t\t\treturn (d[0] * (cellDimension + marginBuffer)) + (hm * (cubeDimension));\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.attr(\"id\", function(d){\n",
       "\t\t\t\t\t\treturn \"rect\" + d[3];\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.attr(\"width\", function(d){\n",
       "\t\t\t\t\t\treturn cubeDimension;\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.attr(\"height\", function(d){\n",
       "\t\t\t\t\t\treturn cubeDimension;\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.attr(\"opacity\", function(d){\n",
       "\t\t\t\t\t\treturn 1;\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.attr(\"fill\", function(d){\n",
       "\t\t\t\t\t\treturn (\"black\");\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.attr(\"class\", function(d){\n",
       "\t\t\t\t\t\tpredicted_label = \"predicted_label_\" + d[1];\n",
       "\t\t\t\t\t\ttrue_label = \"true_label_\" + d[0];\n",
       "\t\t\t\t\t\treturn true_label + \" \" + predicted_label;\n",
       "\t\t\t\t});\n",
       "\n",
       "\n",
       "\n",
       "\t\t\t\td3.select(\"#review\")\n",
       "\t\t\t\t\t.select(\"testList\")\n",
       "\t\t\t\t\t.selectAll(\"rect\")\n",
       "\t\t\t\t\t.data(\n",
       "\t\t\t\t\t\tdataset.filter(d => d[0] != d[1]),\n",
       "\t\t\t\t\t\tfunction(d){\n",
       "\t\t\t\t\t\t\treturn d[3];\n",
       "\t\t\t\t\t\t}\n",
       "\t\t\t\t\t)\n",
       "\t\t\t\t\t.enter()\n",
       "\t\t\t\t\t.append(\"li\")\n",
       "\t\t\t\t\t.attr(\"id\", function(d){\n",
       "\t\t\t\t\t\treturn \"text\" + d[3];\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t\t.html(function(d){\n",
       "\t\t\t\t\t\ttable = \"<table><tr>\"\n",
       "\t\t\t\t\t\ttable += \"<td> True: \";\n",
       "\t\t\t\t\t\ttable += parseInt(d[0]); //getType(d[0]);\n",
       "\t\t\t\t\t\ttable += \"</td>\"\n",
       "\t\t\t\t\t\ttable += \"<td> Predict: \";\n",
       "\t\t\t\t\t\ttable += parseInt(d[1]); //getType(d[1]);\n",
       "\t\t\t\t\t\ttable += \"</td>\"\n",
       "\t\t\t\t\t\ttable += \"<td>\" + d[2].substr(0,200); + \"</td>\"\n",
       "\t\t\t\t\t\ttable += \"</tr> </table>\"\n",
       "\t\t\t\t\t\treturn  table;\n",
       "\t\t\t\t});\n",
       "\n",
       "\n",
       "\n",
       "\t\t\t\trect.on(\"click\", function(d_on){\n",
       "\t\t\t\t\td3.select(\"#review\")\n",
       "\t\t\t\t\t\t.select(\"#testList\")\n",
       "\t\t\t\t\t\t.html(\"\");\n",
       "\t\t\t\t\tif(!this.classList.contains(\"past\")){\n",
       "\t\t\t\t\t\td3.selectAll(\".past\")\n",
       "\t\t\t\t\t\t\t.attr(\"fill\", \"pink\")\n",
       "\t\t\t\t\t\t\t.classed(\"past\", false);\n",
       "\t\t\t\t\t\td3.selectAll(\".reclick\")\n",
       "\t\t\t\t\t\t\t.attr(\"fill\", \"pink\")\n",
       "\t\t\t\t\t\t\t.classed(\"reclick\", false)\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t\tif(!this.classList.contains(\"reclick\")){\n",
       "\t\t\t\t\t\td3.selectAll(\".reclick\")\n",
       "\t\t\t\t\t\t\t.attr(\"fill\", \"pink\")\n",
       "\t\t\t\t\t\t\t.classed(\"reclick\", false);\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t\td3.select(this);\n",
       "\t\t\t\t\ttextId = \"\";\n",
       "\t\t\t\t\tx = \".\" + this.classList[0];\n",
       "\t\t\t\t\ty = \".\" + this.classList[1];\n",
       "\t\t\t\t\ttest = x + y;\n",
       "\t\t\t\t\tx1 = x.charAt(x.length - 1);\n",
       "\t\t\t\t\ty1 = y.charAt(y.length - 1);\n",
       "\t\t\t\t\tif(this.classList.contains(\"past\")){\n",
       "\t\t\t\t\t\td3.select(this)\n",
       "\t\t\t\t\t\t\t.classed(\"reclick\", true)\n",
       "\t\t\t\t\t\tId = this.id;\n",
       "\t\t\t\t\t\ttextId = \"#text\" + Id.substring(4);\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t\td3.selectAll(test)\n",
       "\t\t\t\t\t\t.attr(\"fill\", \"purple\")\n",
       "\t\t\t\t\t\t.classed(\"past\", \"true\");\n",
       "\t\t\t\t\td3.select(\"#review\")\n",
       "\t\t\t\t\t\t.select(\"#testList\")\n",
       "\t\t\t\t\t\t.selectAll(\"rect\")\n",
       "\t\t\t\t\t\t.data(\n",
       "\t\t\t\t\t\t\tdataset\n",
       "\t\t\t\t\t\t\t\t.filter(d => d[0] == x1)\n",
       "\t\t\t\t\t\t\t\t.filter(d => d[1] == y1),\n",
       "\t\t\t\t\t\t\t\tfunction(d){\n",
       "\t\t\t\t\t\t\t\t\treturn d[3];\n",
       "\t\t\t\t\t\t\t\t}\n",
       "\t\t\t\t\t\t)\n",
       "\t\t\t\t\t\t.enter()\n",
       "\t\t\t\t\t\t.append(\"li\")\n",
       "\t\t\t\t\t\t.attr(\"id\", function(d){\n",
       "\t\t\t\t\t\t\treturn \"text\" + d[3];\n",
       "\t\t\t\t\t\t})\n",
       "\t\t\t\t\t\t.html(function(d){\n",
       "\t\t\t\t\t\t\ttable = \"<table><tr>\"\n",
       "\t\t\t\t\t\t\ttable += \"<td> True: \";\n",
       "\t\t\t\t\t\t\ttable += parseInt(d[0]); //getType(d[0]);\n",
       "\t\t\t\t\t\t\ttable += \"</td>\"\n",
       "\t\t\t\t\t\t\ttable += \"<td> Predict: \";\n",
       "\t\t\t\t\t\t\ttable += parseInt(d[1]); //getType(d[1]);\n",
       "\t\t\t\t\t\t\ttable += \"</td>\"\n",
       "\t\t\t\t\t\t\ttable += \"<td>\" + d[2].substr(0,200); + \"</td>\"\n",
       "\t\t\t\t\t\t\ttable += \"</tr> </table>\"\n",
       "\t\t\t\t\t\t\treturn table;\n",
       "\t\t\t\t\t});\n",
       "\t\t\t\t\td3.select(\"#review\")\n",
       "\t\t\t\t\t\t.select(\"testList\")\n",
       "\t\t\t\t\t\t.selectAll(\"li\")\n",
       "\t\t\t\t\t\t.on(\"mouseover\", function(d_on){\n",
       "\t\t\t\t\t\t\td3.select(this)\n",
       "\t\t\t\t\t\t\t\t.classed(\"lighthigh\", true)\n",
       "\t\t\t\t\t\t\t\tid = this.id;\n",
       "\t\t\t\t\t\t\t\trectId = \"#rect\" + id.substring(4);\n",
       "\t\t\t\t\t\t\t\td3.selectAll(rectId)\n",
       "\t\t\t\t\t\t\t\t\t.attr(\"fill\", \"green\");\n",
       "\t\t\t\t\t\t})\n",
       "\t\t\t\t\t\t.on(\"mouseout\", function(d_on){\n",
       "\t\t\t\t\t\t\td3.select(this)\n",
       "\t\t\t\t\t\t\t\t.classed(\"lighthigh\", false)\n",
       "\t\t\t\t\t\t\t\tid = this.id;\n",
       "\t\t\t\t\t\t\t\trectId = \"#rect\" + id.substring(4);\n",
       "\t\t\t\t\t\t\t\td3.selectAll(rectId)\n",
       "\t\t\t\t\t\t\t\t\t.attr(\"fill\", \"purple\");\n",
       "\t\t\t\t\t});\n",
       "\t\t\t\t});\n",
       "\n",
       "\n",
       "\t\t\t\td3.select(\"#review\")\n",
       "\t\t\t\t\t.select(\"#testList\")\n",
       "\t\t\t\t\t.selectAll(\"li\")\n",
       "\t\t\t\t\t.on(\"mouseover\", function(d_on){\n",
       "\t\t\t\t\t\td3.select(this)\n",
       "\t\t\t\t\t\t\t.classed(\"lighthigh\", true)\n",
       "\t\t\t\t\t\t\tid = this.id;\n",
       "\t\t\t\t\t\t\trectId = \"#rect\" + id.substring(4);\n",
       "\t\t\t\t\t\t\td3.selectAll(rectId)\n",
       "\t\t\t\t\t\t\t\t.attr(\"fill\", \"green\");\n",
       "\t\t\t\t\t})\n",
       "\t\t\t\t  .on(\"mouseout\", function(d_on){\n",
       "\t\t\t\t\t\td3.select(this)\n",
       "\t\t\t\t\t\t\t.classed(\"lighthigh\", false)\n",
       "\t\t\t\t\t\t\tid = this.id;\n",
       "\t\t\t\t\t\t\trectId = \"#rect\" + id.substring(4);\n",
       "\t\t\t\t\t\t\td3.selectAll(rectId)\n",
       "\t\t\t\t\t\t\t\t.attr(\"fill\", \"pink\");\n",
       "\t\t\t\t});\n",
       "\n",
       "\n",
       "\t\t\t});\n",
       "\t\t})\n",
       "\t\t </script>\n",
       "\t\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = mlvs.ConfusionMatrix(full_path_extended)\n",
    "cm.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
