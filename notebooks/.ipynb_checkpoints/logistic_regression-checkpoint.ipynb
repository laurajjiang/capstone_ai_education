{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression is Classification algorithm commonly used in Machine Learning. It allows categorizing data into discrete classes by learning the relationship from a given set of labeled data. It learns a linear relationship from the given dataset and then introduces a non-linearity in the form of the Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "def sigmoid(z): \n",
    "    return 1 / (1 + np.exp( - z)) \n",
    "  \n",
    "plt.plot(np.arange(-5, 5, 0.1), sigmoid(np.arange(-5, 5, 0.1))) \n",
    "plt.title('Visualization of the Sigmoid Function') \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "The iris flower dataset is available on Keras dataset API(https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) The following code loads the Iris dataset to your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# import iris data from sklearn datasets library\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "5                  5.4               3.9                1.7               0.4   \n",
      "6                  4.6               3.4                1.4               0.3   \n",
      "7                  5.0               3.4                1.5               0.2   \n",
      "8                  4.4               2.9                1.4               0.2   \n",
      "9                  4.9               3.1                1.5               0.1   \n",
      "10                 5.4               3.7                1.5               0.2   \n",
      "11                 4.8               3.4                1.6               0.2   \n",
      "12                 4.8               3.0                1.4               0.1   \n",
      "13                 4.3               3.0                1.1               0.1   \n",
      "14                 5.8               4.0                1.2               0.2   \n",
      "15                 5.7               4.4                1.5               0.4   \n",
      "16                 5.4               3.9                1.3               0.4   \n",
      "17                 5.1               3.5                1.4               0.3   \n",
      "18                 5.7               3.8                1.7               0.3   \n",
      "19                 5.1               3.8                1.5               0.3   \n",
      "20                 5.4               3.4                1.7               0.2   \n",
      "21                 5.1               3.7                1.5               0.4   \n",
      "22                 4.6               3.6                1.0               0.2   \n",
      "23                 5.1               3.3                1.7               0.5   \n",
      "24                 4.8               3.4                1.9               0.2   \n",
      "25                 5.0               3.0                1.6               0.2   \n",
      "26                 5.0               3.4                1.6               0.4   \n",
      "27                 5.2               3.5                1.5               0.2   \n",
      "28                 5.2               3.4                1.4               0.2   \n",
      "29                 4.7               3.2                1.6               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "120                6.9               3.2                5.7               2.3   \n",
      "121                5.6               2.8                4.9               2.0   \n",
      "122                7.7               2.8                6.7               2.0   \n",
      "123                6.3               2.7                4.9               1.8   \n",
      "124                6.7               3.3                5.7               2.1   \n",
      "125                7.2               3.2                6.0               1.8   \n",
      "126                6.2               2.8                4.8               1.8   \n",
      "127                6.1               3.0                4.9               1.8   \n",
      "128                6.4               2.8                5.6               2.1   \n",
      "129                7.2               3.0                5.8               1.6   \n",
      "130                7.4               2.8                6.1               1.9   \n",
      "131                7.9               3.8                6.4               2.0   \n",
      "132                6.4               2.8                5.6               2.2   \n",
      "133                6.3               2.8                5.1               1.5   \n",
      "134                6.1               2.6                5.6               1.4   \n",
      "135                7.7               3.0                6.1               2.3   \n",
      "136                6.3               3.4                5.6               2.4   \n",
      "137                6.4               3.1                5.5               1.8   \n",
      "138                6.0               3.0                4.8               1.8   \n",
      "139                6.9               3.1                5.4               2.1   \n",
      "140                6.7               3.1                5.6               2.4   \n",
      "141                6.9               3.1                5.1               2.3   \n",
      "142                5.8               2.7                5.1               1.9   \n",
      "143                6.8               3.2                5.9               2.3   \n",
      "144                6.7               3.3                5.7               2.5   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     target  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "5         0  \n",
      "6         0  \n",
      "7         0  \n",
      "8         0  \n",
      "9         0  \n",
      "10        0  \n",
      "11        0  \n",
      "12        0  \n",
      "13        0  \n",
      "14        0  \n",
      "15        0  \n",
      "16        0  \n",
      "17        0  \n",
      "18        0  \n",
      "19        0  \n",
      "20        0  \n",
      "21        0  \n",
      "22        0  \n",
      "23        0  \n",
      "24        0  \n",
      "25        0  \n",
      "26        0  \n",
      "27        0  \n",
      "28        0  \n",
      "29        0  \n",
      "..      ...  \n",
      "120       2  \n",
      "121       2  \n",
      "122       2  \n",
      "123       2  \n",
      "124       2  \n",
      "125       2  \n",
      "126       2  \n",
      "127       2  \n",
      "128       2  \n",
      "129       2  \n",
      "130       2  \n",
      "131       2  \n",
      "132       2  \n",
      "133       2  \n",
      "134       2  \n",
      "135       2  \n",
      "136       2  \n",
      "137       2  \n",
      "138       2  \n",
      "139       2  \n",
      "140       2  \n",
      "141       2  \n",
      "142       2  \n",
      "143       2  \n",
      "144       2  \n",
      "145       2  \n",
      "146       2  \n",
      "147       2  \n",
      "148       2  \n",
      "149       2  \n",
      "\n",
      "[150 rows x 5 columns]\n",
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# To use tenforflow 1.x functions, import compact v1\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.enable_eager_execution()\n",
    "# # # make unable to use tensorflow v2.x functions to avoid crash\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# change to pandas dataframe\n",
    "iris = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "iris = iris.astype({\"target\": int })\n",
    "\n",
    "print(iris)\n",
    "print(iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t<style> \n",
       "\t.table {\n",
       "      border-collapse: collapse;\n",
       "      border: #d0d4d5 solid 1px;\n",
       "      border-spacing: 0px;\n",
       "      font: Arial;\n",
       "      text-align: center;\n",
       "      padding: 5px;\n",
       "      width: 100%;\n",
       "    }\n",
       "    \n",
       "\n",
       "    .headerRowStyle {\n",
       "      background-color: #fff;\n",
       "      border-bottom: 3px solid #ccc;\n",
       "      color: #4078a9;\n",
       "      font-size: 14px;\n",
       "      height: 48px;\n",
       "      line-height: 14px;\n",
       "      padding: 10px 5px 5px 5px\n",
       "    }\n",
       "    \n",
       "    .headerCellStyle {\n",
       "      border-left: 1px solid #d0d4d5;\n",
       "    }\n",
       "    \n",
       "    .tableRowStyle {\n",
       "      border-bottom: 1px solid #d0d4d5;\n",
       "      color: #565656;\n",
       "    }\n",
       "\t\t </style>\n",
       "\t\t<h1> Vector Visualization </h1>\n",
       "\t\t<div class=\"tables\"></div>\n",
       "\n",
       "\t\t<script> \n",
       "\t\tconsole.log(\"Loading JavaScript...\")\n",
       "\t\tconsole.log(\"Loaded Data:\")\n",
       "        var dname = \"libraries/iris.json\"\n",
       "\n",
       "    function colorPicker(value) {\n",
       "        if (value == \"Iris-setosa\") {\n",
       "        return \"#7aa25c\";\n",
       "        } else if (value == \"Iris-versicolor\") {\n",
       "        return \"#f4f85e\";\n",
       "        } else {\n",
       "        return \"#d84b2a\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "\n",
       "    function checkNumberIfFloat(value) {\n",
       "        return Number(value) === value && value % 1 !== 0;\n",
       "    }\n",
       "\n",
       "    d3.json(\"libraries/iris.json\", function(dataSet) {\n",
       "      var div = d3.select('.tables');\n",
       "\n",
       "      // append a table to the div\n",
       "      var table = div.append(\"table\")\n",
       "        .attr({\n",
       "          id: \"sample\",\n",
       "          class: 'table'\n",
       "        })\n",
       "        .classed(\"display\", true);\n",
       "\n",
       "      // append a header to the table\n",
       "      var thead = table.append(\"thead\")\n",
       "\n",
       "      // append a body to the table\n",
       "      var tbody = table.append(\"tbody\")\n",
       "\n",
       "      // append a row to the header\n",
       "      var theadRow = thead.append(\"tr\")\n",
       "        .attr({\n",
       "          class: 'headerRowStyle'\n",
       "        });\n",
       "\n",
       "      // return a selection of cell elements in the header row\n",
       "      // attribute (join) data to the selection\n",
       "      // update (enter) the selection with nodes that have data\n",
       "      // append the cell elements to the header row\n",
       "      // return the text string for each item in the data array\n",
       "      theadRow.selectAll(\"th\")\n",
       "        .data(d3.keys(dataSet[0]))\n",
       "        .enter()\n",
       "        .append(\"th\")\n",
       "        .text(function(d) {\n",
       "          return d;\n",
       "        });\n",
       "\n",
       "      // table body rows\n",
       "      var tableBodyRows = tbody.selectAll(\"tr\")\n",
       "        .data(dataSet)\n",
       "        .enter()\n",
       "        .append(\"tr\")\n",
       "        .attr({\n",
       "          class: 'tableRowStyle'\n",
       "        });\n",
       "\n",
       "      //table body row cells\n",
       "      tableBodyRows.selectAll(\"td\")\n",
       "        .data(function(d) {\n",
       "          return d3.values(d);\n",
       "        })\n",
       "        .enter()\n",
       "        .append(\"td\")\n",
       "        .text(function(d) {\n",
       "          return d;\n",
       "        })\n",
       "        .append(function(d) {\n",
       "          return createSVG(d);\n",
       "        });\n",
       "        \n",
       "    })\n",
       "\n",
       "    function createSVG(d) {\n",
       "      var w = 75;\n",
       "      var h = 75;\n",
       "\n",
       "      var kpi = document.createElement(\"div\");\n",
       "\n",
       "      var svg = d3.select(kpi).append(\"svg\")\n",
       "        .attr({\n",
       "          width: w,\n",
       "          height: h\n",
       "        });\n",
       "        \n",
       "      var elem = svg.selectAll(\"div\")\n",
       "        .data([d]);\n",
       "\n",
       "      var elemEnter = elem.enter()\n",
       "        .append(\"g\");\n",
       "\n",
       "    \n",
       "        if( checkNumberIfFloat(d) || Number.isInteger(d)){\n",
       "            var la = (d/7);\n",
       "            elemEnter.append(\"rect\")\n",
       "                .attr({\n",
       "                x: 25,\n",
       "                y: 10, //this basically makes the svg start from the button instead of the top\n",
       "                width: 60*la,\n",
       "                height: 20\n",
       "                })\n",
       "                .style(\"fill\", \"#4078a9\");\n",
       "\n",
       "            elemEnter.append(\"text\")\n",
       "                .style(\"fill\", \"blue\")\n",
       "                .attr(\"dy\", 30)\n",
       "                .attr(\"dx\", 25)\n",
       "        }else{ \n",
       "            elemEnter.append(\"circle\")\n",
       "                .attr({\n",
       "                cx: 28,\n",
       "                cy: 25,\n",
       "                r: 20\n",
       "                })\n",
       "                .style(\"fill\", colorPicker);\n",
       "\n",
       "            elemEnter.append(\"text\")\n",
       "                .style(\"fill\", \"blue\")\n",
       "                .attr(\"dy\", 30)\n",
       "                .attr(\"dx\", 25)\n",
       "\n",
       "        }\n",
       "      return kpi;\n",
       "    }\n",
       "\t\t </script>\n",
       "\t\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_directory = \"libraries/\"\n",
    "output_filename = \"iris.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import libraries.vector as vector\n",
    "\n",
    "cm = vector.Visualization(full_path)\n",
    "cm.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## Explore the data \n",
    "\n",
    "Let's take a moment to understand the format of the data. Each data contains sepal length, sepal width, petal length, petal width and a corresponding species label. The label is an integer value of either 0 or 1, where 0 is a 'Iris-setosa', and 1 is a 'Iris-versicolo'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check head of dataframe\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a scatter plot with sepal length and width between two iris species in the dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(iris['sepal length (cm)'][:50], iris['sepal width (cm)'][:50], label='Iris-setosa')\n",
    "plt.scatter(iris['sepal length (cm)'][51:], iris['sepal width (cm)'][51:], label='Iris-versicolo')\n",
    "plt.scatter(iris['sepal length (cm)'][101:], iris['sepal width (cm)'][101:], label='Iris-virginica')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5bmxzE0Fobd"
   },
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create x value as the features and y value as species (labels) from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop(labels=['target'], axis=1).values\n",
    "y = iris['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a seed to get reproducibility for numpy and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, split the dataset into trainset (60%) and testset (40%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use random choice from numpy library to set dataset randomly\n",
    "train_data = np.random.choice(len(x), round(len(x) * 0.6), replace=False)\n",
    "test_data = np.array(list(set(range(len(x))) - set(train_data)))\n",
    "\n",
    "# separate the dataset into features and labels\n",
    "x_train = x[train_data]\n",
    "y_train = y[train_data]\n",
    "x_test = x[test_data]\n",
    "y_test = y[test_data]\n",
    "\n",
    "# the number of labels\n",
    "num_labels = 3 \n",
    "\n",
    "# the number of features: sepal length & width, petal length & width\n",
    "num_features = 4\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to normalize the feature values in the dataset.\n",
    "Normalization is optional for logistic regression. However, the main goal of normalizing features is to help convergence of the technique used for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalization function\n",
    "def min_max_normalization(data):\n",
    "    col_max = np.max(data, axis=0)\n",
    "    col_min = np.min(data, axis=0)\n",
    "    return np.divide(data - col_min, col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized processing, must be placed after the data set segmentation, \n",
    "# otherwise the test set will be affected by the training set\n",
    "x_train = min_max_normalization(x_train)\n",
    "x_test = min_max_normalization(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## Build the model\n",
    "With the pre-processed dataset, we start to build the model with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin building the model framework\n",
    "# Declare the variables that need to be learned and initialization\n",
    "# Weight of shape [4, 3]\n",
    "\n",
    "W = tf.Variable(tf.ones([num_features, num_labels]), name=\"weight\")\n",
    "\n",
    "# Bias of shape [3], the total number of classes.\n",
    "\n",
    "b = tf.Variable(tf.zeros([num_labels]), name=\"bias\")\n",
    "\n",
    "#W = tf.Variable(tf.random.normal([2, 1], mean=0.0))\n",
    "#b = tf.Variable(tf.random.normal([1], mean=0.0))\n",
    "# The tf 2.x doesn't need to use tf.global_variables_initializer() and place holders\n",
    "#init = tf.global_variables_initializer()\n",
    "#sess = tf.Session()\n",
    "#sess.run(init)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the logistic regression to learn about variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (Wx + b).\n",
    "\n",
    "def logistic_regression(x):\n",
    "\n",
    "    # Apply softmax to normalize the logits to a probability distribution.\n",
    "\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "attachments": {
    "log_loss.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer\n",
    "\n",
    "Let's declare the loss function\n",
    "\n",
    "The loss function is critical for machine & deep learning models.\n",
    "The loss function for linear regression is squared loss, but the loss function for logistic regression is Log Loss, which is defined as follows:\n",
    "\n",
    "![log_loss.PNG](attachment:log_loss.PNG)\n",
    "\n",
    "where:\n",
    "\n",
    "* (x,y) ∈ D is the data set containing many labeled examples, which are  (x,y) pairs.\n",
    "* y is the label in a labeled example. Since this is logistic regression, every value of y must either be 0 or 1.\n",
    "* y' is the predicted value (somewhere between 0 and 1), given the set of features in x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy loss function.\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "\n",
    "    # Encode label to a one hot vector.\n",
    "\n",
    "    y_true = tf.one_hot(y_true, depth=num_labels)\n",
    "\n",
    "    # Clip prediction values to avoid log(0) error.\n",
    "\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "\n",
    "    # Compute cross-entropy.\n",
    "\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before train our model, we need to set the parameters: learning rate, batch size, and the number of epoch interations.\n",
    "\n",
    "\n",
    "* Learning rate is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient.\n",
    "\n",
    "* Batch size defines the number of samples that will be propagated through the network.\n",
    "\n",
    "* An epoch is a full iteration over samples during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "batch_size = 32\n",
    "epoch_iteration_num = 2000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define optimizer to find optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metric.\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "\n",
    "# Predicted class is the index of the highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "\n",
    "train_data=tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "\n",
    "train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "\n",
    "# create variables to store result\n",
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# Optimization process. \n",
    "\n",
    "def run_optimization(x, y):\n",
    "\n",
    "# Wrap computation inside a GradientTape for automatic differentiation.\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "\n",
    "        pred = logistic_regression(x)\n",
    "\n",
    "        loss = cross_entropy(pred, y)\n",
    "        losses.append(loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "\n",
    "  \n",
    "\n",
    "    # Update W and b following gradients.\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for the given number of steps.\n",
    "\n",
    "for epoch, (batch_x, batch_y) in enumerate(train_data.take(epoch_iteration_num), 1):\n",
    "\n",
    "    # Run the optimization to update W and b values.\n",
    "\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    train_pred = logistic_regression(batch_x)\n",
    "    train_acc = accuracy(train_pred, batch_y)\n",
    "    test_pred = logistic_regression(x_test)\n",
    "    test_acc = accuracy(test_pred, y_test)\n",
    "    # recode the result\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    \n",
    "\n",
    "    if epoch % display_step == 0:\n",
    "\n",
    "        #pred = logistic_regression(batch_x)\n",
    "\n",
    "        loss = cross_entropy(train_pred, batch_y)\n",
    "\n",
    "\n",
    "        #print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
    "        print('epoch: {:4d} loss: {:5f} train accuracy: {:5f} test accuracy: {:5f}'.format(epoch, loss,\n",
    "                                                                          train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make plot of the loss per epoch from the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs, 'b-', label='train accuracy')\n",
    "plt.plot(test_accs, 'r-', label='test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on validation set.\n",
    "model_prediction = []\n",
    "testing_predictions = ((logistic_regression(x_test) > 0.5).numpy()).astype(\"int32\")\n",
    "\n",
    "for i in range(len(testing_predictions)):\n",
    "    for j in range(len(testing_predictions[i])):\n",
    "        if testing_predictions[i][j] == 1:\n",
    "            model_prediction.append(j)\n",
    "\n",
    "pred = logistic_regression(x_test)\n",
    "probas = pred.numpy()\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_directory = \"libraries/\"\n",
    "output_filename = \"predict_LR.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "data = []\n",
    "data.extend([{\n",
    "      'index': i,\n",
    "      'true_label': int(y_test[i]),\n",
    "      'predicted_label': model_prediction[i],\n",
    "      'confidence_score': probas.tolist()[i],\n",
    "      'text': str(x_test.tolist()[i])\n",
    "  } for i in range(len(testing_predictions))])\n",
    "\n",
    "\n",
    "with open(full_path, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=8, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------easy way (don't run yet) -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "# Predict probabilities\n",
    "probs_y=classifier.predict_proba(x_test)\n",
    "### Print results \n",
    "probs_y = np.round(probs_y, 2)\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(y_test, y_pred, probs_y[:,0], probs_y[:,1], probs_y[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "import seaborn as sns\n",
    "# confusion matrix sns heatmap \n",
    "ax = plt.axes()\n",
    "df_cm = cm\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 30}, fmt='d',cmap=\"Blues\", ax = ax )\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
