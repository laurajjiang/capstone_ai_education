{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic4_occAAiAT"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-01-21T02:30:55.844731Z",
     "iopub.status.busy": "2021-01-21T02:30:55.844046Z",
     "iopub.status.idle": "2021-01-21T02:30:55.845988Z",
     "shell.execute_reply": "2021-01-21T02:30:55.846501Z"
    },
    "id": "ioaprt5q5US7"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-01-21T02:30:55.850608Z",
     "iopub.status.busy": "2021-01-21T02:30:55.849897Z",
     "iopub.status.idle": "2021-01-21T02:30:55.851787Z",
     "shell.execute_reply": "2021-01-21T02:30:55.852215Z"
    },
    "id": "yCl0eTNH5RS3"
   },
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Text classification with TensorFlow Hub: Movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKY4XMc9o8iB"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/text_classification_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/s?module-type=text-embedding\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub models</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "This notebook classifies movie reviews as *positive* or *negative* using the text of the review. This is an example of *binary*—or two-class—classification, an important and widely applicable kind of machine learning problem.\n",
    "\n",
    "The tutorial demonstrates the basic application of transfer learning with [TensorFlow Hub](https://tfhub.dev) and Keras.\n",
    "\n",
    "We'll use the [IMDB dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/). These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are *balanced*, meaning they contain an equal number of positive and negative reviews. \n",
    "\n",
    "This notebook uses [`tf.keras`](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow, and [`tensorflow_hub`](https://www.tensorflow.org/hub), a library for loading trained models from [TFHub](https://tfhub.dev) in a single line of code. For a more advanced text classification tutorial using `tf.keras`, see the [MLCC Text Classification Guide](https://developers.google.com/machine-learning/guides/text-classification/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T02:30:55.861328Z",
     "iopub.status.busy": "2021-01-21T02:30:55.860661Z",
     "iopub.status.idle": "2021-01-21T02:30:57.340057Z",
     "shell.execute_reply": "2021-01-21T02:30:57.340555Z"
    },
    "id": "IHTzYqKZ7auw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: patool in /home/owen/.local/lib/python3.9/site-packages (1.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-hub\n",
    "!pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment to Disable usage of GPU\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-21T02:30:57.346597Z",
     "iopub.status.busy": "2021-01-21T02:30:57.345866Z",
     "iopub.status.idle": "2021-01-21T02:31:05.548690Z",
     "shell.execute_reply": "2021-01-21T02:31:05.549175Z"
    },
    "id": "2ew7HTbPpCJH",
    "outputId": "3fab584d-e995-457b-e721-b03b12b80bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.4.1\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import libraries.mlvislib as mlvs\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "The IMDB dataset is available on [imdb reviews](https://www.tensorflow.org/datasets/catalog/imdb_reviews) or on [TensorFlow datasets](https://www.tensorflow.org/datasets). The following code downloads the IMDB dataset to your machine (or the colab runtime):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "execution": {
     "iopub.execute_input": "2021-01-21T02:31:05.554665Z",
     "iopub.status.busy": "2021-01-21T02:31:05.554003Z",
     "iopub.status.idle": "2021-01-21T02:32:00.389224Z",
     "shell.execute_reply": "2021-01-21T02:32:00.388420Z"
    },
    "id": "zXXx5Oc3pOmN",
    "outputId": "56456b56-a9d7-46b4-ffb2-2e90c3cc59c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the training set into 60% and 40%, so we'll end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# import patoolib\n",
    "\n",
    "# patoolib.extract_archive(\"dataset/IMDB Dataset.csv.zip\", outdir='/dataset/')\n",
    "dataset = pd.read_csv(\"dataset/IMDB Dataset.csv\")\n",
    "dataset = dataset[:25000]\n",
    "\n",
    "dataset.isnull().values.any()\n",
    "dataset.shape\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## Explore the data \n",
    "\n",
    "Let's take a moment to understand the format of the data. Each example is a sentence representing the movie review and a corresponding label. The sentence is not preprocessed in any way. The label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review.\n",
    "\n",
    "Let's print first 10 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "rmexS4Gt8BnN",
    "outputId": "2c7592ea-ef80-42cc-ecdd-ac855cc76b0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    One of the other reviewers has mentioned that ...\n",
       "1    A wonderful little production. <br /><br />The...\n",
       "2    I thought this was a wonderful way to spend ti...\n",
       "3    Basically there's a family where a little boy ...\n",
       "4    Petter Mattei's \"Love in the Time of Money\" is...\n",
       "5    Probably my all-time favorite movie, a story o...\n",
       "6    I sure would like to see a resurrection of a u...\n",
       "7    This show was an amazing, fresh & innovative i...\n",
       "8    Encouraged by the positive comments about this...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='sentiment', data=dataset)\n",
    "dataset[\"review\"][:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5bmxzE0Fobd"
   },
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-21T02:32:00.394689Z",
     "iopub.status.busy": "2021-01-21T02:32:00.393954Z",
     "iopub.status.idle": "2021-01-21T02:32:00.443785Z",
     "shell.execute_reply": "2021-01-21T02:32:00.444242Z"
    },
    "id": "QtTS4kpEpjbi",
    "outputId": "8a23a4bc-6e5a-4bf6-c55e-b0c0e50ac045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18930    \"Wired\" would have to rate as one of the ten w...\n",
      "2791     A 'Wes Craven presents' movie from 1995, direc...\n",
      "388      A lovely little B picture with all the usual J...\n",
      "22764    I am going to go out on a limb, and actually d...\n",
      "24934    To put in simple words or rather a word, would...\n",
      "                               ...                        \n",
      "21575    I enjoyed a lot watching this movie. It has a ...\n",
      "5390     I can't knock this film too terribly, because ...\n",
      "860      This production was quite a surprise for me. I...\n",
      "15795    This is a decent movie. Although little bit sh...\n",
      "23654    Another very good Mann flick thanks to the fat...\n",
      "Name: review, Length: 15000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "def cleanText(sentence):\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def preProcess(text):\n",
    "    # Make lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace non-text characters with spaces\n",
    "    nonText = string.punctuation + (\"\")\n",
    "    text = text.translate(str.maketrans(nonText, ' ' * (len(nonText))))\n",
    "\n",
    "    # Tokenize\n",
    "    words = text.split()\n",
    "\n",
    "    return words\n",
    "\n",
    "#x = []\n",
    "#sentences = list(dataset['review'])\n",
    "#for sen in sentences:\n",
    "#    x.append(cleanText(sen))\n",
    "\n",
    "y = dataset['sentiment']\n",
    "\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset['review'], y, test_size=0.4, random_state=42)\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "The neural network is created by stacking layers—this requires three main architectural decisions:\n",
    "\n",
    "* How to represent the text?\n",
    "* How many layers to use in the model?\n",
    "* How many *hidden units* to use for each layer?\n",
    "\n",
    "In this example, the input data consists of sentences. The labels to predict are either 0 or 1.\n",
    "\n",
    "One way to represent the text is to convert sentences into embeddings vectors. We can use a pre-trained text embedding as the first layer, which will have three advantages:\n",
    "\n",
    "*   we don't have to worry about text preprocessing,\n",
    "*   we can benefit from transfer learning,\n",
    "*   the embedding has a fixed size, so it's simpler to process.\n",
    "\n",
    "For this example we will use a **pre-trained text embedding model** from [TensorFlow Hub](https://tfhub.dev) called [google/nnlm-en-dim50/2](https://tfhub.dev/google/nnlm-en-dim50/2).\n",
    "\n",
    "There are many other pre-trained text embeddings from TFHub that can be used in this tutorial:\n",
    "\n",
    "* [google/nnlm-en-dim128/2](https://tfhub.dev/google/nnlm-en-dim128/2) - trained with the same NNLM architecture on the same data as [google/nnlm-en-dim50/2](https://tfhub.dev/google/nnlm-en-dim50/2), but with a larger embedding dimension. Larger dimensional embeddings can improve on your task but it may take longer to train your model.\n",
    "* [google/nnlm-en-dim128-with-normalization/2](https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2) - the same as [google/nnlm-en-dim128/2](https://tfhub.dev/google/nnlm-en-dim128/2), but with additional text normalization such as removing punctuation. This can help if the text in your task contains additional characters or punctuation.\n",
    "* [google/universal-sentence-encoder/4](https://tfhub.dev/google/universal-sentence-encoder/4) - a much larger model yielding 512 dimensional embeddings trained with a deep averaging network (DAN) encoder.\n",
    "\n",
    "And many more! Find more [text embedding models](https://tfhub.dev/s?module-type=text-embedding) on TFHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In2nDpTLkgKa"
   },
   "source": [
    "Let's first create a Keras layer that uses a TensorFlow Hub model to embed the sentences, and try it out on a couple of input examples. Note that no matter the length of the input text, the output shape of the embeddings is: `(num_examples, embedding_dimension)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T02:32:00.458022Z",
     "iopub.status.busy": "2021-01-21T02:32:00.456993Z",
     "iopub.status.idle": "2021-01-21T02:32:09.087601Z",
     "shell.execute_reply": "2021-01-21T02:32:09.088050Z"
    },
    "id": "_NUbzVeYkgcO"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-17c388f539ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muniversal_sentence_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder/4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m hub_layer = hub.KerasLayer(universal_sentence_embedding, input_shape=[], \n\u001b[0m\u001b[1;32m      4\u001b[0m                            dtype=tf.string, trainable=True)\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# hub_layer = hub.KerasLayer(embedding, input_shape=[],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Expected before TF2.4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mset_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[1;32m    105\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m   \"\"\"\n\u001b[0;32m--> 859\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[1;32m    890\u001b[0m                             ckpt_options, filters)\n\u001b[1;32m    891\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, filters)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                   self._checkpoint_options).expect_partial()\n\u001b[1;32m    486\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mgraph_view\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         options=options)\n\u001b[0;32m-> 1336\u001b[0;31m     base.CheckpointPosition(\n\u001b[0m\u001b[1;32m   1337\u001b[0m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    970\u001b[0m       \u001b[0mpython_saveables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_python_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     restore_ops.extend(\n\u001b[0;32m--> 972\u001b[0;31m         current_position.checkpoint.restore_saveables(\n\u001b[0m\u001b[1;32m    973\u001b[0m             tensor_saveables, python_saveables))\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    305\u001b[0m             (\"Saveable keys changed when validating. Got back %s, was \"\n\u001b[1;32m    306\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[0;32m--> 307\u001b[0;31m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0m\u001b[1;32m    308\u001b[0m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[1;32m    309\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m           \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    113\u001b[0m     for saveable, restored_tensors in zip(self._saveable_objects,\n\u001b[1;32m    114\u001b[0m                                           structured_restored_tensors):\n\u001b[0;32m--> 115\u001b[0;31m       restore_ops[saveable.name] = saveable.restore(\n\u001b[0m\u001b[1;32m    116\u001b[0m           restored_tensors, restored_shapes=None)\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Copy the restored tensor to the variable's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m       \u001b[0mrestored_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[1;32m    132\u001b[0m           self.handle_op, self._var_shape, restored_tensor)\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3931\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3932\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3933\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3934\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]"
     ]
    }
   ],
   "source": [
    "# embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "universal_sentence_embedding = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "hub_layer = hub.KerasLayer(universal_sentence_embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "# hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "#                            dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfSbV6igl1EH"
   },
   "source": [
    "Let's now build the full model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-21T02:32:09.101252Z",
     "iopub.status.busy": "2021-01-21T02:32:09.099886Z",
     "iopub.status.idle": "2021-01-21T02:32:09.513013Z",
     "shell.execute_reply": "2021-01-21T02:32:09.513480Z"
    },
    "id": "xpKOoWgu-llD",
    "outputId": "aac8311f-c33e-4585-f2de-8374e887642d"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(hub_layer)\n",
    "# Adjusting the below value will change the amount of 'bars' loaded into the Barcode Vis\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PbKQ6mucuKL"
   },
   "source": [
    "The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "1. The first layer is a TensorFlow Hub layer. This layer uses a pre-trained Saved Model to map a sentence into its embedding vector. The pre-trained text embedding model that we are using ([google/nnlm-en-dim50/2](https://tfhub.dev/google/nnlm-en-dim50/2)) splits the sentence into tokens, embeds each token and then combines the embedding. The resulting dimensions are: `(num_examples, embedding_dimension)`. For this NNLM model, the `embedding_dimension` is 50.\n",
    "2. This fixed-length output vector is piped through a fully-connected (`Dense`) layer with 16 hidden units.\n",
    "3. The last layer is densely connected with a single output node.\n",
    "\n",
    "Let's compile the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4EqVWg4-llM"
   },
   "source": [
    "### Loss function and optimizer\n",
    "\n",
    "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs logits (a single-unit layer with a linear activation), we'll use the `binary_crossentropy` loss function.\n",
    "\n",
    "This isn't the only choice for a loss function, you could, for instance, choose `mean_squared_error`. But, generally, `binary_crossentropy` is better for dealing with probabilities—it measures the \"distance\" between probability distributions, or in our case, between the ground-truth distribution and the predictions.\n",
    "\n",
    "Later, when we are exploring regression problems (say, to predict the price of a house), we will see how to use another loss function called mean squared error.\n",
    "\n",
    "Now, configure the model to use an optimizer and a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T02:32:09.528133Z",
     "iopub.status.busy": "2021-01-21T02:32:09.527041Z",
     "iopub.status.idle": "2021-01-21T02:32:09.536804Z",
     "shell.execute_reply": "2021-01-21T02:32:09.537223Z"
    },
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Train the model for 10 epochs in mini-batches of 512 samples. This is 10 iterations over all samples in the `x_train` and `y_train` tensors. While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data\n",
    "\n",
    "Here, we define the Callback function used to extact data from the model as it fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libraries.extractioncallback as excb\n",
    "\n",
    "extractor = excb.CallbackDataExtractor(\n",
    "    model = model,\n",
    "    layer = 1,\n",
    "    validation_data = (x_test, y_test),\n",
    "    rec_int_values = True,\n",
    "    is_bin = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-21T02:32:09.542485Z",
     "iopub.status.busy": "2021-01-21T02:32:09.541473Z",
     "iopub.status.idle": "2021-01-21T02:32:27.978728Z",
     "shell.execute_reply": "2021-01-21T02:32:27.978091Z"
    },
    "id": "tXSGrjWZ-llW",
    "outputId": "3384f82c-91d0-4d89-ea09-0cf2486a2f68",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=512, epochs=10, verbose=1, validation_split=0.2, shuffle=False, callbacks=[extractor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epoch_output = extractor.get_testing_results()\n",
    "\n",
    "# extractor_predictions = extractor.get_stored_predictions()\n",
    "# edited_predictions = []\n",
    "# for epoch in extractor_predictions:\n",
    "#     epoch_predictions = []\n",
    "#     for item in epoch:\n",
    "#         epoch_predictions.append((item > .5).astype(\"int32\"))\n",
    "#     edited_predictions.append(epoch_predictions)\n",
    "\n",
    "# extractor.set_stored_predictions(edited_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "DhrkmOwP1ssM",
    "outputId": "a827defe-8382-4ae2-9810-ba9af55c739e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# make a prediction\n",
    "testingPredictions = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "confidence_scores = model.predict(x_test, batch_size=512)\n",
    "\n",
    "# scaling confidence scores to range between 0 and 1 with MinMaxScaler \n",
    "scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "scaler.fit(confidence_scores)\n",
    "confidence_scores = scaler.transform(confidence_scores)\n",
    "\n",
    "target_names = ['negative', 'positive']\n",
    "print(classification_report(y_test, testingPredictions, target_names=target_names))\n",
    "testingPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "-waOkzl5Ifba",
    "outputId": "5beae3a7-9d87-4d4d-be6c-4deeb23c5b5e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-21T02:32:27.984454Z",
     "iopub.status.busy": "2021-01-21T02:32:27.983556Z",
     "iopub.status.idle": "2021-01-21T02:32:29.329122Z",
     "shell.execute_reply": "2021-01-21T02:32:29.329592Z"
    },
    "id": "zOMKywn4zReN",
    "outputId": "ad6f9bfd-cc73-462a-85a8-eea66ffc9ae6"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1iEXVTR0Z2t"
   },
   "source": [
    "This fairly naive approach achieves an accuracy of about 87%. With more advanced approaches, the model should get closer to 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "WZ-VeZGPJdGC",
    "outputId": "4a3db1f8-dbbd-40d0-93aa-286212247e71",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {'Actual':    y_test,\n",
    "        'Predicted': testingPredictions.reshape(len(y_test),)\n",
    "        }\n",
    "#print(testingLabels.reshape(len(testingLabels),1))\n",
    "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['Actual'], df['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True,cmap=\"YlGnBu\", fmt='d').set_title('Confusion Matrix of Testing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_output = extractor.get_testing_results()\n",
    "epoch_output[9]['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Writing Epoch Data to JSON...\n",
    "output_directory = \"libraries/\"\n",
    "output_filename = \"hub_nn_epoch_sorted.json\"\n",
    "full_path = os.path.join(output_directory, output_filename)\n",
    "    \n",
    "# Revision of JSON writing...\n",
    "data = {}\n",
    "for i in range(len(epoch_output[0])):\n",
    "    data[i] = {}\n",
    "    data[i]['Num Epochs'] = len(epoch_output)\n",
    "    data[i]['Index'] = i\n",
    "    data[i]['Test Label'] = int(epoch_output[0]['actual'][i])\n",
    "    data[i]['Test Prediction'] = {}\n",
    "    data[i]['Test Confidence Score'] = {}\n",
    "    data[i]['Intermediate Values'] = {}\n",
    "    for j in range(len(epoch_output)):\n",
    "        data[i]['Test Prediction'][j] = int(epoch_output[j]['prediction'][i][0])\n",
    "        data[i]['Test Confidence Score'][j] = float(epoch_output[j]['confidence_score'][i][0])\n",
    "        data[i]['Intermediate Values'][j] = epoch_output[j]['intermediate_values'][i]\n",
    "    data[i]['Test Sentence'] = epoch_output[0]['input'][i]\n",
    "    \n",
    "    \n",
    "with open(full_path, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import libraries.mlvislib as mlvs\n",
    "full_path = 'libraries/hub_nn_epoch_sorted.json'\n",
    "\n",
    "cm = mlvs.ConfusionMatrix(full_path)\n",
    "cm.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_with_hub.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
